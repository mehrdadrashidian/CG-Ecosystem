{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrdadrashidian/CG-Ecosystem/blob/master/Media_Process_Unit_with_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTw8AZd8379",
        "outputId": "5b5786f6-654b-4317-f329-1db456a10d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.11/dist-packages (2.9.10)\n",
            "Requirement already satisfied: Flask-SQLAlchemy in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask>=2.2.5 in /usr/local/lib/python3.11/dist-packages (from Flask-SQLAlchemy) (3.1.0)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.16 in /usr/local/lib/python3.11/dist-packages (from Flask-SQLAlchemy) (2.0.37)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (1.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=2.0.16->Flask-SQLAlchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=2.0.16->Flask-SQLAlchemy) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.2.5->Flask-SQLAlchemy) (3.0.2)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.11/dist-packages (5.2.1)\n",
            "Requirement already satisfied: Flask-Redis in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from Flask-Redis) (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->Flask-Redis) (3.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.13.1)\n",
            "Requirement already satisfied: nsfw-detector in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from nsfw-detector) (11.1.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.7.0 in /usr/local/lib/python3.11/dist-packages (from nsfw-detector) (0.7.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (4.25.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->nsfw-detector) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.1.2)\n",
            "Requirement already satisfied: piexif in /usr/local/lib/python3.11/dist-packages (1.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install Flask\n",
        "!pip install faiss-cpu\n",
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install psycopg2-binary Flask-SQLAlchemy\n",
        "!pip install redis Flask-Redis\n",
        "!pip install pyngrok\n",
        "!pip install pillow\n",
        "!pip install imagehash\n",
        "!pip install nsfw-detector\n",
        "!pip install piexif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n222hxZK9n8P",
        "outputId": "ea157e26-b0d5-4570-8d9d-0f5b37c37a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /mobilenet_v2_140_224.1.zip\n",
            "replace nsfw_model/mobilenet_v2_140_224/class_labels.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y A\n",
            " extracting: nsfw_model/mobilenet_v2_140_224/class_labels.txt  \n",
            "replace nsfw_model/mobilenet_v2_140_224/frozen_graph.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/frozen_graph.pb  \n",
            "replace nsfw_model/mobilenet_v2_140_224/saved_model.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.h5  \n",
            "replace nsfw_model/mobilenet_v2_140_224/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.pb  \n",
            "replace nsfw_model/mobilenet_v2_140_224/saved_model.tflite? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.tflite  \n",
            "replace nsfw_model/mobilenet_v2_140_224/saved_model_weights.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model_weights.h5  \n",
            "replace nsfw_model/mobilenet_v2_140_224/training_results.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/training_results.txt  \n",
            "replace nsfw_model/mobilenet_v2_140_224/variables/variables.data-00000-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.data-00000-of-00002  \n",
            "replace nsfw_model/mobilenet_v2_140_224/variables/variables.data-00001-of-00002? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.data-00001-of-00002  \n",
            "replace nsfw_model/mobilenet_v2_140_224/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.index  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/group1-shard1of5.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard1of5.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/group1-shard2of5.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard2of5.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/group1-shard3of5.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard3of5.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/group1-shard4of5.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard4of5.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/group1-shard5of5.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard5of5.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model/model.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/model.json  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard1of2.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard1of2.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard2of2.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard2of2.bin  \n",
            "replace nsfw_model/mobilenet_v2_140_224/web_model_quantized/model.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/model.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip /mobilenet_v2_140_224.1.zip -d nsfw_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_favr6vXzui",
        "outputId": "d8556d15-471a-4cb9-8024-07be9dc9fc1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ مدل NSFW با موفقیت بارگذاری شد!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "nsfw_model = tf.saved_model.load(model_path)\n",
        "\n",
        "print(\"✅ مدل NSFW با موفقیت بارگذاری شد!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAsQHHwaUstC",
        "outputId": "787ad4ce-f98c-40e4-ce88-2550ebae205f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 محتویات پوشه مدل: ['saved_model.tflite', 'frozen_graph.pb', 'saved_model_weights.h5', 'saved_model.pb', 'assets', 'variables', 'web_model_quantized', 'training_results.txt', 'web_model', 'class_labels.txt', 'saved_model.h5']\n",
            "📂 محتویات web_model_quantized: ['group1-shard2of2.bin', 'model.json', 'group1-shard1of2.bin']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_root = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "print(\"📂 محتویات پوشه مدل:\", os.listdir(model_root))\n",
        "\n",
        "web_model_path = os.path.join(model_root, \"web_model_quantized\")\n",
        "if os.path.exists(web_model_path):\n",
        "    print(\"📂 محتویات web_model_quantized:\", os.listdir(web_model_path))\n",
        "else:\n",
        "    print(\"❌ پوشه web_model_quantized وجود ندارد!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G_QQWu_9osE",
        "outputId": "becadba8-f9ed-4a5b-a6d6-b4df5dfb23a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ فایل مدل پیدا شد!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224/saved_model.h5\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ فایل مدل پیدا شد!\")\n",
        "else:\n",
        "    print(\"❌ فایل مدل در مسیر مشخص‌شده وجود ندارد.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8bJD_Xl-Yec",
        "outputId": "3ed195e2-5b0e-465f-db8c-30471f1455b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-hub==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (4.25.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow-hub==0.7.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-312gxcQ-j9M",
        "outputId": "9a1fe099-6abe-4dc5-db71-2fdd57f77a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/162.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7035cf397dec42058b0872e123b343a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.70.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "y\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "ml_dtypes",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "4ccb9671886746eb844a7c109de4a9d2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install protobuf==3.20.*\n",
        "!pip install tensorflow==2.14.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jazZeG2Mtb0O",
        "outputId": "dced0517-ca5e-4e5c-8fec-b6bc56a822a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql is already the newest version (14+238).\n",
            "postgresql-contrib is already the newest version (14+238).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install postgresql postgresql-contrib\n",
        "!service postgresql start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1oKyW0ttu4n",
        "outputId": "5305ec23-5abb-4c75-cdab-191e68e80487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR:  role \"myuser\" already exists\n",
            "ERROR:  database \"mydb\" already exists\n"
          ]
        }
      ],
      "source": [
        "!sudo -u postgres psql -c \"CREATE USER myuser WITH PASSWORD 'mypassword';\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE mydb OWNER myuser;\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VZqtoLx8mte",
        "outputId": "4fd50411-f339-4947-d6e9-a081ed8466e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:From <ipython-input-1-0fe8ec8eef34>:86: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.saved_model.load` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 اجرا شده در: NgrokTunnel: \"https://fada-34-80-110-253.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:38:53] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:38:53] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:38:54] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:38:58] \"POST /calculate_nudity HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:00] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:03] \"POST /search HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/pan.jpg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/56ee384b7ada0e960c9576c0e883a8c2_low.webp HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/56b72279-9d2d-41f1-894a-3fbbea9cb967.jpg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/photo_2025-02-05_19-21-58.jpg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/1-intro-photo-final.jpg HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 18:39:04] \"GET /static/uploads/masha.png HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "!pkill -9 ngrok\n",
        "from flask import Flask, request, jsonify, render_template_string, send_from_directory\n",
        "from pyngrok import ngrok\n",
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import tensorflow.compat.v1 as tf\n",
        "import timm\n",
        "from sqlalchemy import create_engine, Column, Integer, String, LargeBinary, text\n",
        "from sqlalchemy.orm import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import logging\n",
        "import uuid  # برای تولید نام یکتا\n",
        "import os\n",
        "import piexif\n",
        "from PIL import Image, PngImagePlugin\n",
        "import logging\n",
        "import datetime\n",
        "import binascii\n",
        "\n",
        "# تنظیم logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# تنظیمات پایگاه داده PostgreSQL\n",
        "DATABASE_URL = \"postgresql://myuser:mypassword@localhost/mydb\"\n",
        "Base = declarative_base()\n",
        "\n",
        "# مدل دیتابیس\n",
        "class ImageEmbedding(Base):\n",
        "    __tablename__ = 'image_embeddings'\n",
        "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
        "    filename = Column(String, unique=True, nullable=False)\n",
        "    image_data = Column(LargeBinary, nullable=False)  # ذخیره تصویر به‌صورت باینری\n",
        "    embedding = Column(LargeBinary, nullable=False)   # ذخیره بردار ویژگی به‌صورت بایت\n",
        "    nudity_score = Column(String, nullable=True)  # اضافه کردن نمره محتوای نامناسب\n",
        "\n",
        "engine = create_engine(DATABASE_URL)\n",
        "SessionLocal = sessionmaker(bind=engine)\n",
        "Base.metadata.create_all(engine)\n",
        "\n",
        "# بررسی و افزودن ستون‌های مفقود به دیتابیس\n",
        "def check_and_add_columns():\n",
        "    session = SessionLocal()\n",
        "    try:\n",
        "        result = session.execute(text(\"SELECT column_name FROM information_schema.columns WHERE table_name='image_embeddings' AND column_name='nudity_score'\"))\n",
        "        if not result.fetchone():\n",
        "            session.execute(text(\"ALTER TABLE image_embeddings ADD COLUMN nudity_score VARCHAR;\"))\n",
        "            session.commit()\n",
        "            logging.info(\"✅ ستون nudity_score به دیتابیس اضافه شد.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در بررسی/اضافه کردن ستون‌ها: {e}\")\n",
        "    finally:\n",
        "        session.close()\n",
        "\n",
        "check_and_add_columns()\n",
        "\n",
        "# تنظیمات اولیه\n",
        "UPLOAD_FOLDER = 'static/uploads'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "NGROK_TOKEN = \"2srSLcJso0gWDqNC7YWfGjNkHF0_5quu1vDqrrQtrjCFytuN3\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# تنظیم FAISS\n",
        "D = 512\n",
        "index = faiss.IndexFlatL2(D)\n",
        "index_path = \"faiss.index\"\n",
        "if os.path.exists(index_path):\n",
        "    index = faiss.read_index(index_path)\n",
        "\n",
        "# تنظیم مدل ویژگی‌برداری\n",
        "feature_extractor = timm.create_model(\"tf_efficientnet_b0\", pretrained=True, num_classes=0)\n",
        "feature_extractor.eval()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# تنظیم مدل NSFW\n",
        "tf.disable_eager_execution()\n",
        "session_tf = tf.Session()\n",
        "session_tf.run(tf.global_variables_initializer())\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "with session_tf.as_default():\n",
        "    with session_tf.graph.as_default():\n",
        "        nsfw_model = tf.saved_model.loader.load(session_tf, [tf.saved_model.SERVING], model_path)\n",
        "        infer = nsfw_model.signature_def[\"serving_default\"]\n",
        "        input_tensor_name = infer.inputs[\"input\"].name\n",
        "        output_tensor_name = infer.outputs[\"prediction\"].name\n",
        "        input_tensor = session_tf.graph.get_tensor_by_name(input_tensor_name)\n",
        "        output_tensor = session_tf.graph.get_tensor_by_name(output_tensor_name)\n",
        "\n",
        "def detect_nudity(image_path):\n",
        "    with session_tf.as_default():\n",
        "        with session_tf.graph.as_default():\n",
        "            img = Image.open(image_path).convert(\"RGB\").resize((224, 224))\n",
        "            img_array = np.array(img).astype(np.float32) / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            result = session_tf.run(output_tensor, feed_dict={input_tensor: img_array})\n",
        "            return {\"sexy\": f\"{round(float(result[0][4]) * 100, 2)}%\", \"porn\": f\"{round(float(result[0][3]) * 100, 2)}%\"}\n",
        "\n",
        "def generate_image_embedding(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "        img = np.array(img).astype('float32') / 255.0\n",
        "        img = torch.tensor(img).permute(2, 0, 1).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            embedding = feature_extractor(img).numpy()\n",
        "        embedding = embedding.reshape(1, -1)\n",
        "        if embedding.shape[1] > D:\n",
        "            embedding = embedding[:, :D]\n",
        "        elif embedding.shape[1] < D:\n",
        "            padding = np.zeros((1, D - embedding.shape[1]), dtype=embedding.dtype)\n",
        "            embedding = np.concatenate([embedding, padding], axis=1)\n",
        "        if not isinstance(embedding, np.ndarray):\n",
        "            logging.error(f\"❌ خروجی embedding مقدار نامعتبری دارد: {type(embedding)}\")\n",
        "            return None\n",
        "        logging.info(f\"✅ استخراج embedding موفقیت‌آمیز بود. شکل نهایی: {embedding.shape}\")\n",
        "        return embedding.astype('float32')\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در استخراج embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "# اصلاح تابع بررسی تصویر تکراری\n",
        "def check_duplicate_image(filename, embedding, sim_threshold=0.9):\n",
        "    session_db = SessionLocal()\n",
        "    try:\n",
        "        # بررسی بر اساس نام فایل\n",
        "        duplicate_name = session_db.query(ImageEmbedding).filter_by(filename=filename).first()\n",
        "        if duplicate_name:\n",
        "            session_db.close()\n",
        "            return {\n",
        "                \"duplicate\": True,\n",
        "                \"reason\": \"filename\",\n",
        "                \"message\": f\"عکس دیگری با این نام و فرمت پیشتر ثبت شده است: {filename}\"\n",
        "            }\n",
        "        # بررسی شباهت embedding برای تمام تصاویر (نام‌های متفاوت)\n",
        "        embeddings_db, filenames = load_embeddings_from_db()\n",
        "        if embeddings_db.shape[0] == 0:\n",
        "            session_db.close()\n",
        "            return {\"duplicate\": False}\n",
        "        normalized_query = embedding / np.linalg.norm(embedding)\n",
        "        norms = np.linalg.norm(embeddings_db, axis=1, keepdims=True)\n",
        "        norms[norms == 0] = 1\n",
        "        normalized_embeddings = embeddings_db / norms\n",
        "        cosine_similarities = np.dot(normalized_query, normalized_embeddings.T)[0]\n",
        "        similar_indices = np.where(cosine_similarities >= sim_threshold)[0]\n",
        "        if similar_indices.size > 0:\n",
        "            similar_files = [filenames[i] for i in similar_indices]\n",
        "            session_db.close()\n",
        "            return {\n",
        "                \"duplicate\": True,\n",
        "                \"reason\": \"embedding\",\n",
        "                \"message\": f\"تصویر با مشابهت بالای 90 درصد: {', '.join(similar_files)}\",\n",
        "                \"similar_files\": similar_files\n",
        "            }\n",
        "        session_db.close()\n",
        "        return {\"duplicate\": False}\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در بررسی تصویر تکراری: {e}\")\n",
        "        session_db.close()\n",
        "        return {\"duplicate\": False}\n",
        "\n",
        "def save_to_database(filename, image_path, embedding, nudity_score):\n",
        "    try:\n",
        "        session_db = SessionLocal()\n",
        "        existing_entry = session_db.query(ImageEmbedding).filter_by(filename=filename).first()\n",
        "        if existing_entry:\n",
        "            logging.warning(f\"⚠️ فایل {filename} از قبل در دیتابیس وجود دارد.\")\n",
        "            session_db.close()\n",
        "            return False\n",
        "        embedding_bytes = embedding.tobytes()\n",
        "        with open(image_path, \"rb\") as img_file:\n",
        "            image_data = img_file.read()\n",
        "        new_entry = ImageEmbedding(\n",
        "            filename=filename,\n",
        "            image_data=image_data,\n",
        "            embedding=embedding_bytes,\n",
        "            nudity_score=str(nudity_score)\n",
        "        )\n",
        "        session_db.add(new_entry)\n",
        "        session_db.commit()\n",
        "        logging.info(f\"✅ تصویر {filename} با موفقیت در دیتابیس ذخیره شد.\")\n",
        "        session_db.close()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        session_db.rollback()\n",
        "        logging.error(f\"❌ خطا در ذخیره اطلاعات در دیتابیس: {e}\")\n",
        "        session_db.close()\n",
        "        return False\n",
        "\n",
        "def load_embeddings_from_db():\n",
        "    session_db = SessionLocal()\n",
        "    images = session_db.query(ImageEmbedding).all()\n",
        "    session_db.close()\n",
        "    embeddings = [np.frombuffer(img.embedding, dtype=np.float32) for img in images]\n",
        "    filenames = [img.filename for img in images]\n",
        "    return np.vstack(embeddings), filenames\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return filename.lower().endswith(('png', 'jpg', 'jpeg', 'webp'))\n",
        "\n",
        "# --------------------------\n",
        "# اضافه کردن endpoint برای محاسبه نودیتی (بدون ثبت تصویر)\n",
        "# --------------------------\n",
        "@app.route('/calculate_nudity', methods=['POST'])\n",
        "def calculate_nudity():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"فایل ارسال نشده است.\"})\n",
        "    file = request.files['file']\n",
        "    if file.filename == '' or not allowed_file(file.filename):\n",
        "        return jsonify({\"error\": \"نوع فایل معتبر نیست.\"})\n",
        "    temp_filename = \"temp_\" + uuid.uuid4().hex + \"_\" + file.filename\n",
        "    file_path = os.path.join(UPLOAD_FOLDER, temp_filename)\n",
        "    file.save(file_path)\n",
        "    try:\n",
        "        nudity_score = detect_nudity(file_path)\n",
        "        os.remove(file_path)\n",
        "        return jsonify({\"nudity_score\": nudity_score})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": \"خطا در محاسبه نودیتی\", \"detail\": str(e)})\n",
        "\n",
        "# --------------------------\n",
        "# صفحه HTML اصلی به عنوان Template\n",
        "# --------------------------\n",
        "html_page = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"fa\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <title>مدیریت تصاویر</title>\n",
        "  <style>\n",
        "    /* استایل‌های پایه */\n",
        "    body {\n",
        "      font-family: Arial, sans-serif;\n",
        "      background-color: #f2f2f2;\n",
        "      margin: 0;\n",
        "      padding: 0;\n",
        "      direction: rtl;\n",
        "      text-align: center;\n",
        "    }\n",
        "    .container {\n",
        "      max-width: 800px;\n",
        "      margin: 0 auto;\n",
        "      padding: 20px;\n",
        "    }\n",
        "    h1 {\n",
        "      color: #333;\n",
        "    }\n",
        "    /* ناحیه درگ‌اند-دراپ */\n",
        "    .drop-zone {\n",
        "      border: 2px dashed #cccccc;\n",
        "      border-radius: 10px;\n",
        "      padding: 40px;\n",
        "      background-color: #fff;\n",
        "      cursor: pointer;\n",
        "      transition: border-color 0.3s ease;\n",
        "    }\n",
        "    .drop-zone.hover {\n",
        "      border-color: #555;\n",
        "    }\n",
        "    #preview {\n",
        "      max-width: 100%;\n",
        "      max-height: 300px;\n",
        "      margin-top: 20px;\n",
        "      display: none;\n",
        "    }\n",
        "    /* استایل دکمه‌ها */\n",
        "    .btn {\n",
        "      display: inline-block;\n",
        "      margin: 10px;\n",
        "      padding: 10px 20px;\n",
        "      font-size: 16px;\n",
        "      color: #fff;\n",
        "      background-color: #007BFF;\n",
        "      border: none;\n",
        "      border-radius: 5px;\n",
        "      cursor: pointer;\n",
        "    }\n",
        "    .btn:hover {\n",
        "      background-color: #0056b3;\n",
        "    }\n",
        "    /* استایل تامبنیل‌های تصاویر */\n",
        "    .thumbnail {\n",
        "      width: 150px;\n",
        "      height: 150px;\n",
        "      object-fit: cover;\n",
        "      border: 2px solid #ddd;\n",
        "      border-radius: 5px;\n",
        "      cursor: pointer;\n",
        "      transition: border-color 0.3s ease;\n",
        "    }\n",
        "    .thumbnail:hover {\n",
        "      border-color: #007BFF;\n",
        "    }\n",
        "    .thumbnails-container {\n",
        "      display: flex;\n",
        "      flex-wrap: wrap;\n",
        "      justify-content: center;\n",
        "      margin-top: 20px;\n",
        "    }\n",
        "    .thumb-container {\n",
        "      display: inline-block;\n",
        "      text-align: center;\n",
        "      margin: 10px;\n",
        "    }\n",
        "    /* استایل مدال نمایش تصویر کامل */\n",
        "    .modal {\n",
        "      display: none;\n",
        "      position: fixed;\n",
        "      z-index: 1000;\n",
        "      left: 0;\n",
        "      top: 0;\n",
        "      width: 100%;\n",
        "      height: 100%;\n",
        "      overflow: auto;\n",
        "      background-color: rgba(0,0,0,0.7);\n",
        "    }\n",
        "    .modal-content {\n",
        "      margin: 5% auto;\n",
        "      display: block;\n",
        "      max-width: 80%;\n",
        "    }\n",
        "    .close {\n",
        "      position: absolute;\n",
        "      top: 20px;\n",
        "      right: 35px;\n",
        "      color: #f1f1f1;\n",
        "      font-size: 40px;\n",
        "      font-weight: bold;\n",
        "      cursor: pointer;\n",
        "    }\n",
        "    /* پیام‌ها */\n",
        "    #message {\n",
        "      margin-top: 20px;\n",
        "      font-size: 16px;\n",
        "    }\n",
        "    /* نمایش نودیتی */\n",
        "    #nudity-score {\n",
        "      margin-top: 10px;\n",
        "      font-size: 18px;\n",
        "      font-weight: bold;\n",
        "      color: #444;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <h1>مدیریت تصاویر</h1>\n",
        "\n",
        "    <!-- ناحیه انتخاب فایل (درگ‌اند-دراپ یا کلیک برای انتخاب) -->\n",
        "    <div id=\"drop-zone\" class=\"drop-zone\">\n",
        "      <p>برای انتخاب تصویر کلیک کنید یا تصویر را بکشید و رها کنید</p>\n",
        "      <input type=\"file\" id=\"file-input\" accept=\"image/*\" style=\"display: none;\">\n",
        "      <img id=\"preview\" src=\"#\" alt=\"پیش‌نمایش تصویر\">\n",
        "    </div>\n",
        "    <!-- نمایش نودیتی -->\n",
        "    <div id=\"nudity-score\"></div>\n",
        "\n",
        "    <!-- دکمه ثبت (به جای آپلود) -->\n",
        "    <div>\n",
        "      <button id=\"upload-btn\" class=\"btn\">ثبت</button>\n",
        "      <button id=\"search-btn\" class=\"btn\">جستجو</button>\n",
        "    </div>\n",
        "\n",
        "    <!-- نمایش پیام‌ها -->\n",
        "    <div id=\"message\"></div>\n",
        "\n",
        "    <!-- نمایش نتایج جستجو (تامبنیل‌های تصاویر مشابه) -->\n",
        "    <div id=\"results\" class=\"thumbnails-container\"></div>\n",
        "  </div>\n",
        "\n",
        "  <!-- مدال برای نمایش تصویر کامل -->\n",
        "  <div id=\"myModal\" class=\"modal\">\n",
        "    <span class=\"close\">&times;</span>\n",
        "    <img class=\"modal-content\" id=\"modal-img\">\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    // انتخاب عناصر صفحه\n",
        "    const dropZone = document.getElementById('drop-zone');\n",
        "    const fileInput = document.getElementById('file-input');\n",
        "    const preview = document.getElementById('preview');\n",
        "    const uploadBtn = document.getElementById('upload-btn');\n",
        "    const searchBtn = document.getElementById('search-btn');\n",
        "    const messageDiv = document.getElementById('message');\n",
        "    const resultsDiv = document.getElementById('results');\n",
        "    const nudityScoreDiv = document.getElementById('nudity-score');\n",
        "\n",
        "    let selectedFile = null;\n",
        "\n",
        "    // کلیک روی ناحیه درگ‌اند-دراپ فایل ورودی را فعال می‌کند\n",
        "    dropZone.addEventListener('click', () => {\n",
        "      fileInput.click();\n",
        "    });\n",
        "\n",
        "    // زمانی که کاربر فایلی انتخاب کرد، پیش‌نمایش آن نمایش داده می‌شود\n",
        "    fileInput.addEventListener('change', (e) => {\n",
        "      if(e.target.files.length) {\n",
        "        selectedFile = e.target.files[0];\n",
        "        displayPreview(selectedFile);\n",
        "        computeNudity(selectedFile);\n",
        "      }\n",
        "    });\n",
        "\n",
        "    // رویدادهای درگ‌اند-دراپ\n",
        "    dropZone.addEventListener('dragover', (e) => {\n",
        "      e.preventDefault();\n",
        "      dropZone.classList.add('hover');\n",
        "    });\n",
        "\n",
        "    dropZone.addEventListener('dragleave', (e) => {\n",
        "      e.preventDefault();\n",
        "      dropZone.classList.remove('hover');\n",
        "    });\n",
        "\n",
        "    dropZone.addEventListener('drop', (e) => {\n",
        "      e.preventDefault();\n",
        "      dropZone.classList.remove('hover');\n",
        "      if(e.dataTransfer.files.length) {\n",
        "        selectedFile = e.dataTransfer.files[0];\n",
        "        fileInput.files = e.dataTransfer.files; // همگام‌سازی ورودی فایل\n",
        "        displayPreview(selectedFile);\n",
        "        computeNudity(selectedFile);\n",
        "      }\n",
        "    });\n",
        "\n",
        "    // تابع نمایش پیش‌نمایش تصویر\n",
        "    function displayPreview(file) {\n",
        "      const reader = new FileReader();\n",
        "      reader.onload = function(e) {\n",
        "        preview.src = e.target.result;\n",
        "        preview.style.display = 'block';\n",
        "      }\n",
        "      reader.readAsDataURL(file);\n",
        "    }\n",
        "\n",
        "    // تابع محاسبه نودیتی از طریق endpoint جدید\n",
        "    function computeNudity(file) {\n",
        "      const formData = new FormData();\n",
        "      formData.append('file', file);\n",
        "\n",
        "      fetch('/calculate_nudity', {\n",
        "        method: 'POST',\n",
        "        body: formData\n",
        "      })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "        if(data.error) {\n",
        "          nudityScoreDiv.innerHTML = `<p style=\"color:red;\">${data.error}</p>`;\n",
        "        } else {\n",
        "          // نمایش نودیتی به صورت زیبا (می‌توانید استایل دلخواه را اضافه کنید)\n",
        "          const score = data.nudity_score;\n",
        "          nudityScoreDiv.innerHTML = `<p>نودیتی: sexy = ${score.sexy} | porn = ${score.porn}</p>`;\n",
        "        }\n",
        "      })\n",
        "      .catch(err => {\n",
        "        nudityScoreDiv.innerHTML = `<p style=\"color:red;\">خطا در محاسبه نودیتی.</p>`;\n",
        "      });\n",
        "    }\n",
        "\n",
        "    // رویداد کلیک دکمه ثبت (آپلود)\n",
        "    uploadBtn.addEventListener('click', () => {\n",
        "      if(!selectedFile) {\n",
        "        alert(\"لطفاً ابتدا یک تصویر انتخاب کنید.\");\n",
        "        return;\n",
        "      }\n",
        "      const formData = new FormData();\n",
        "      formData.append('file', selectedFile);\n",
        "\n",
        "      fetch('/', {\n",
        "        method: 'POST',\n",
        "        body: formData\n",
        "      })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "        if(data.error) {\n",
        "          messageDiv.innerHTML = `<p style=\"color:red;\">${data.error}</p>`;\n",
        "        } else {\n",
        "          messageDiv.innerHTML = `<p style=\"color:green;\">ثبت با موفقیت انجام شد. نودیتی: ${JSON.stringify(data.nudity_score)}</p>`;\n",
        "        }\n",
        "      })\n",
        "      .catch(err => {\n",
        "        messageDiv.innerHTML = `<p style=\"color:red;\">خطا در ثبت تصویر.</p>`;\n",
        "      });\n",
        "    });\n",
        "\n",
        "    // رویداد کلیک دکمه جستجو\n",
        "    searchBtn.addEventListener('click', () => {\n",
        "      if(!selectedFile) {\n",
        "        alert(\"لطفاً ابتدا یک تصویر انتخاب کنید.\");\n",
        "        return;\n",
        "      }\n",
        "      const formData = new FormData();\n",
        "      formData.append('file', selectedFile);\n",
        "\n",
        "      fetch('/search', {\n",
        "        method: 'POST',\n",
        "        body: formData\n",
        "      })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "        resultsDiv.innerHTML = ''; // پاکسازی نتایج قبلی\n",
        "        if(data.error) {\n",
        "          messageDiv.innerHTML = `<p style=\"color:red;\">${data.error}</p>`;\n",
        "        } else {\n",
        "          // اگر نتایج مشابه وجود داشته باشد\n",
        "          if(data.similar_files) {\n",
        "            data.similar_files.forEach(item => {\n",
        "              const container = document.createElement('div');\n",
        "              container.className = 'thumb-container';\n",
        "\n",
        "              const img = document.createElement('img');\n",
        "              img.src = `/static/uploads/${item.filename}`;\n",
        "              img.alt = item.filename;\n",
        "              img.classList.add('thumbnail');\n",
        "              img.addEventListener('click', () => {\n",
        "                openModal(img.src);\n",
        "              });\n",
        "\n",
        "              const caption = document.createElement('div');\n",
        "              caption.textContent = `شباهت: ${item.similarity}%`;\n",
        "\n",
        "              container.appendChild(img);\n",
        "              container.appendChild(caption);\n",
        "              resultsDiv.appendChild(container);\n",
        "            });\n",
        "          } else if(data.best_match) {\n",
        "            const container = document.createElement('div');\n",
        "            container.className = 'thumb-container';\n",
        "\n",
        "            const img = document.createElement('img');\n",
        "            img.src = `/static/uploads/${data.best_match.filename}`;\n",
        "            img.alt = data.best_match.filename;\n",
        "            img.classList.add('thumbnail');\n",
        "            img.addEventListener('click', () => {\n",
        "              openModal(img.src);\n",
        "            });\n",
        "\n",
        "            const caption = document.createElement('div');\n",
        "            caption.textContent = `شباهت: ${data.best_match.similarity}%`;\n",
        "\n",
        "            container.appendChild(img);\n",
        "            container.appendChild(caption);\n",
        "            resultsDiv.appendChild(container);\n",
        "          }\n",
        "        }\n",
        "      })\n",
        "      .catch(err => {\n",
        "        messageDiv.innerHTML = `<p style=\"color:red;\">خطا در جستجو.</p>`;\n",
        "      });\n",
        "    });\n",
        "\n",
        "    // مدال نمایش تصویر کامل\n",
        "    const modal = document.getElementById(\"myModal\");\n",
        "    const modalImg = document.getElementById(\"modal-img\");\n",
        "    const closeModal = document.getElementsByClassName(\"close\")[0];\n",
        "\n",
        "    function openModal(src) {\n",
        "      modal.style.display = \"block\";\n",
        "      modalImg.src = src;\n",
        "    }\n",
        "\n",
        "    closeModal.onclick = function() {\n",
        "      modal.style.display = \"none\";\n",
        "    }\n",
        "\n",
        "    window.onclick = function(event) {\n",
        "      if (event.target == modal) {\n",
        "        modal.style.display = \"none\";\n",
        "      }\n",
        "    }\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_image():\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return jsonify({\"error\": \"فایل ارسال نشده است.\"})\n",
        "        file = request.files['file']\n",
        "        if file.filename == '' or not allowed_file(file.filename):\n",
        "            return jsonify({\"error\": \"نوع فایل معتبر نیست.\"})\n",
        "        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "        file.save(file_path)\n",
        "        nudity_score = detect_nudity(file_path)\n",
        "        embedding = generate_image_embedding(file_path)\n",
        "        if embedding is None:\n",
        "            return jsonify({\"error\": \"❌ استخراج embedding ناموفق بود!\"})\n",
        "        duplicate_result = check_duplicate_image(file.filename, embedding, sim_threshold=0.9)\n",
        "        if duplicate_result[\"duplicate\"]:\n",
        "            if duplicate_result[\"reason\"] == \"filename\":\n",
        "                return jsonify({\"error\": duplicate_result[\"message\"]})\n",
        "            elif duplicate_result[\"reason\"] == \"embedding\":\n",
        "                return jsonify({\"error\": duplicate_result[\"message\"], \"similar_files\": duplicate_result[\"similar_files\"]})\n",
        "        save_to_database(file.filename, file_path, embedding, nudity_score)\n",
        "        index.add(embedding)\n",
        "        faiss.write_index(index, index_path)\n",
        "        return jsonify({\"nudity_score\": nudity_score})\n",
        "    # متد GET صفحه HTML اصلی را نمایش می‌دهد.\n",
        "    return render_template_string(html_page)\n",
        "\n",
        "@app.route('/search', methods=['POST'])\n",
        "def search_image():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"فایل ارسال نشده است.\"})\n",
        "    file = request.files['file']\n",
        "    if file.filename == '' or not allowed_file(file.filename):\n",
        "        return jsonify({\"error\": \"نوع فایل معتبر نیست.\"})\n",
        "    file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "    file.save(file_path)\n",
        "    query_embedding = generate_image_embedding(file_path)\n",
        "    if query_embedding is None:\n",
        "         return jsonify({\"error\": \"خطا در استخراج ویژگی‌ها.\"})\n",
        "    embeddings, filenames = load_embeddings_from_db()\n",
        "    if embeddings.shape[0] == 0:\n",
        "         return jsonify({\"error\": \"هیچ تصویری در پایگاه داده موجود نیست.\"})\n",
        "    #// محاسبه شباهت کسینوسی برای تمامی تصاویر موجود\n",
        "    normalized_query = query_embedding / np.linalg.norm(query_embedding)\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1\n",
        "    normalized_embeddings = embeddings / norms\n",
        "    cosine_similarities = np.dot(normalized_query, normalized_embeddings.T)[0]\n",
        "    similar_indices = np.where(cosine_similarities >= 0.6)[0]  # آستانه 60%\n",
        "\n",
        "    similar_results = []\n",
        "    for idx in similar_indices:\n",
        "         similar_results.append({\n",
        "             \"filename\": filenames[idx],\n",
        "             \"similarity\": round(cosine_similarities[idx] * 100, 2)\n",
        "         })\n",
        "    if similar_results:\n",
        "         return jsonify({\"similar_files\": similar_results})\n",
        "    else:\n",
        "         index_temp = faiss.IndexFlatL2(D)\n",
        "         index_temp.add(embeddings)\n",
        "         _, I_arr = index_temp.search(query_embedding, 1)\n",
        "         best_index = I_arr[0][0]\n",
        "         best_filename = filenames[best_index]\n",
        "         best_similarity = round(cosine_similarities[best_index] * 100, 2)\n",
        "         return jsonify({\"best_match\": {\"filename\": best_filename, \"similarity\": best_similarity}})\n",
        "\n",
        "def is_similar_embedding(embedding, threshold=0.9):\n",
        "    embeddings_db, filenames = load_embeddings_from_db()\n",
        "    if embeddings_db.shape[0] == 0:\n",
        "        return False\n",
        "    normalized_query = embedding / np.linalg.norm(embedding)\n",
        "    norms = np.linalg.norm(embeddings_db, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1\n",
        "    normalized_embeddings = embeddings_db / norms\n",
        "    cosine_sim = np.max(np.dot(normalized_query, normalized_embeddings.T))\n",
        "    logging.info(f\"🔍 بیشترین شباهت (cosine) یافت‌شده: {cosine_sim * 100:.2f}%\")\n",
        "    return cosine_sim >= threshold\n",
        "\n",
        "import datetime\n",
        "import logging\n",
        "from PIL import Image\n",
        "\n",
        "def generate_image_fingerprint(image_path, username):\n",
        "    \"\"\"\n",
        "    تولید فینگرپرینت تصویر با استفاده از الگوریتم dHash و ادغام با یوزرنیم (به صورت هگزا دسیمال) و زمان فراخوانی.\n",
        "\n",
        "    ورودی‌ها:\n",
        "      image_path: مسیر فایل تصویر.\n",
        "      username: نام کاربری (صاحب محتوا).\n",
        "\n",
        "    خروجی:\n",
        "      رشته‌ای شامل فینگرپرینت تصویر به صورت هگزا دسیمال، نام کاربری به صورت هگزا دسیمال،\n",
        "      و تاریخ/ساعت (UTC) فراخوانی تابع به صورت هگزا دسیمال.\n",
        "      (مثلاً: \"f1a2b3c4d5e6f789-756365726e616d-323032353032313031323335393937383132\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # دریافت زمان فراخوانی تابع (به صورت UTC با دقت میکروثانیه)\n",
        "        now_str = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S%f\")\n",
        "        now_hex = now_str.encode('utf-8').hex()\n",
        "\n",
        "        # باز کردن تصویر و تبدیل به grayscale\n",
        "        image = Image.open(image_path).convert(\"L\")\n",
        "        # تغییر اندازه تصویر به 9x8 (برای ایجاد 64 بیت)\n",
        "        image = image.resize((9, 8), Image.ANTIALIAS)\n",
        "        # استخراج مقادیر پیکسلی\n",
        "        pixels = list(image.getdata())\n",
        "        # محاسبه تفاوت بین پیکسل‌های مجاور (الگوریتم dHash)\n",
        "        difference = []\n",
        "        for row in range(8):\n",
        "            for col in range(8):\n",
        "                left_pixel = pixels[row * 9 + col]\n",
        "                right_pixel = pixels[row * 9 + col + 1]\n",
        "                difference.append(1 if left_pixel > right_pixel else 0)\n",
        "        # تبدیل لیست بیتی به عدد 64 بیتی\n",
        "        hash_val = 0\n",
        "        for bit in difference:\n",
        "            hash_val = (hash_val << 1) | bit\n",
        "        # تبدیل عدد به رشته هگزا دسیمال 16 رقمی\n",
        "        image_fingerprint = hex(hash_val)[2:].rjust(16, '0')\n",
        "\n",
        "        # تبدیل یوزرنیم به هگزا دسیمال\n",
        "        username_hex = username.encode('utf-8').hex()\n",
        "\n",
        "        # ادغام فینگرپرینت تصویر، یوزرنیم هگزا شده و زمان (هگزا) با جداکننده \"-\"\n",
        "        combined_fingerprint = image_fingerprint + \"-\" + username_hex + \"-\" + now_hex\n",
        "\n",
        "        return combined_fingerprint\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در تولید فینگرپرینت: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def embed_fingerprint_in_image(image_path, output_path, fingerprint):\n",
        "    \"\"\"\n",
        "    درج فینگرپرینت به عنوان متادیتا در تصویر.\n",
        "\n",
        "    پارامترها:\n",
        "      image_path: مسیر تصویر ورودی.\n",
        "      output_path: مسیر ذخیره تصویر جدید با متادیتای به‌روز شده.\n",
        "      fingerprint: رشته فینگرپرینت (مثلاً حاصل از تابع generate_image_fingerprint).\n",
        "\n",
        "    این تابع بسته به فرمت تصویر (jpeg, jpg, png, bmp, webp) از روش مناسب برای درج متادیتا استفاده می‌کند.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # باز کردن تصویر با PIL\n",
        "        image = Image.open(image_path)\n",
        "        # گرفتن پسوند فایل به صورت حروف کوچک\n",
        "        ext = os.path.splitext(image_path)[1].lower()\n",
        "\n",
        "        if ext in [\".jpeg\", \".jpg\"]:\n",
        "            # برای JPEG/JPG: استفاده از کتابخانه piexif برای درج در فیلد UserComment\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "            else:\n",
        "                exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}, \"thumbnail\": None}\n",
        "            # درج فینگرپرینت در فیلد UserComment در بخش ExifIFD\n",
        "            exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = fingerprint.encode(\"utf-8\")\n",
        "            exif_bytes = piexif.dump(exif_dict)\n",
        "            image.save(output_path, \"jpeg\", exif=exif_bytes)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل JPEG/JPG درج شد.\")\n",
        "\n",
        "        elif ext == \".png\":\n",
        "            # برای PNG: استفاده از PngInfo جهت افزودن تگ متنی\n",
        "            png_info = PngImagePlugin.PngInfo()\n",
        "            png_info.add_text(\"Fingerprint\", fingerprint)\n",
        "            image.save(output_path, \"png\", pnginfo=png_info)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل PNG درج شد.\")\n",
        "\n",
        "        elif ext == \".bmp\":\n",
        "            # برای BMP: فرمت BMP استاندارد پشتیبانی کاملی از متادیتا ندارد.\n",
        "            # تلاش می‌کنیم تا یک کلید comment به info اضافه شود.\n",
        "            if not hasattr(image, \"info\"):\n",
        "                image.info = {}\n",
        "            image.info[\"comment\"] = fingerprint  # ممکن است توسط برخی برنامه‌ها خوانده شود.\n",
        "            image.save(output_path, \"bmp\")\n",
        "            logging.info(\"فینگرپرینت (به صورت comment) در فایل BMP درج شد (توجه: پشتیبانی محدود).\")\n",
        "\n",
        "        elif ext == \".webp\":\n",
        "            # برای WEBP: اگرچه پشتیبانی از متادیتا در این فرمت محدود است،\n",
        "            # می‌توان از exif برای درج اطلاعات استفاده کرد (توجه: تنها برای تصاویر lossless کارایی دارد).\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "            else:\n",
        "                exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}, \"thumbnail\": None}\n",
        "            exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = fingerprint.encode(\"utf-8\")\n",
        "            exif_bytes = piexif.dump(exif_dict)\n",
        "            image.save(output_path, \"WEBP\", exif=exif_bytes)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل WEBP درج شد.\")\n",
        "\n",
        "        else:\n",
        "            logging.error(\"فرمت تصویر پشتیبانی نمی‌شود.\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"خطا در درج فینگرپرینت در متادیتا: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def parse_image_fingerprint(fingerprint):\n",
        "    \"\"\"\n",
        "    تفسیر فینگرپرینت تصویر و استخراج اطلاعات آن.\n",
        "\n",
        "    ورودی:\n",
        "      fingerprint: رشته فینگرپرینت تولید شده.\n",
        "\n",
        "    خروجی:\n",
        "      دیکشنری شامل:\n",
        "        - image_fingerprint: فینگرپرینت تصویر (dHash هگزادسیمال)\n",
        "        - username: نام کاربری استخراج شده از مقدار هگز\n",
        "        - timestamp: تاریخ و زمان استخراج شده از مقدار هگز\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # بررسی ساختار فینگرپرینت\n",
        "        parts = fingerprint.split(\"-\")\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(\"ساختار فینگرپرینت نامعتبر است.\")\n",
        "\n",
        "        image_fingerprint, username_hex, timestamp_hex = parts\n",
        "\n",
        "        # تبدیل هگزا دسیمال یوزرنیم به متن اصلی\n",
        "        username = binascii.unhexlify(username_hex).decode('utf-8')\n",
        "\n",
        "        # تبدیل هگزا دسیمال زمان به مقدار خوانا\n",
        "        timestamp_str = binascii.unhexlify(timestamp_hex).decode('utf-8')\n",
        "        timestamp = datetime.datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S%f\")\n",
        "\n",
        "        return {\n",
        "            \"image_fingerprint\": image_fingerprint,\n",
        "            \"username\": username,\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در تفسیر فینگرپرینت: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# مثال استفاده:\n",
        "# فرض کنید fingerprint از تابع generate_image_fingerprint به دست آمده باشد.\n",
        "# fingerprint = generate_image_fingerprint(\"path/to/image.jpg\", \"myusername\")\n",
        "# embed_fingerprint_in_image(\"path/to/image.jpg\", \"path/to/output_image.jpg\", fingerprint)\n",
        "\n",
        "import os\n",
        "import piexif\n",
        "from PIL import Image, PngImagePlugin\n",
        "import logging\n",
        "\n",
        "def extract_fingerprint_from_image(image_path):\n",
        "    \"\"\"\n",
        "    استخراج فینگرپرینت از متادیتای تصویر.\n",
        "\n",
        "    پارامترها:\n",
        "      image_path: مسیر تصویر.\n",
        "\n",
        "    خروجی:\n",
        "      مقدار فینگرپرینت اگر موجود باشد، در غیر این صورت مقدار None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # باز کردن تصویر با PIL\n",
        "        image = Image.open(image_path)\n",
        "        # گرفتن پسوند فایل به صورت حروف کوچک\n",
        "        ext = os.path.splitext(image_path)[1].lower()\n",
        "\n",
        "        if ext in [\".jpeg\", \".jpg\"]:\n",
        "            # برای JPEG/JPG: خواندن از EXIF\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "                if piexif.ExifIFD.UserComment in exif_dict[\"Exif\"]:\n",
        "                    fingerprint_bytes = exif_dict[\"Exif\"][piexif.ExifIFD.UserComment]\n",
        "                    fingerprint = fingerprint_bytes.decode(\"utf-8\")  # تبدیل به رشته\n",
        "                    return fingerprint\n",
        "            logging.warning(\"فینگرپرینت در متادیتای EXIF فایل JPEG/JPG یافت نشد.\")\n",
        "\n",
        "        elif ext == \".png\":\n",
        "            # برای PNG: خواندن از PngInfo\n",
        "            png_info = image.info\n",
        "            if \"Fingerprint\" in png_info:\n",
        "                return png_info[\"Fingerprint\"]\n",
        "            logging.warning(\"فینگرپرینت در متادیتای PNG یافت نشد.\")\n",
        "\n",
        "        elif ext == \".bmp\":\n",
        "            # برای BMP: خواندن از info\n",
        "            if \"comment\" in image.info:\n",
        "                return image.info[\"comment\"]\n",
        "            logging.warning(\"فینگرپرینت در متادیتای BMP یافت نشد.\")\n",
        "\n",
        "        elif ext == \".webp\":\n",
        "            # برای WEBP: خواندن از EXIF\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "                if piexif.ExifIFD.UserComment in exif_dict[\"Exif\"]:\n",
        "                    fingerprint_bytes = exif_dict[\"Exif\"][piexif.ExifIFD.UserComment]\n",
        "                    fingerprint = fingerprint_bytes.decode(\"utf-8\")  # تبدیل به رشته\n",
        "                    return fingerprint\n",
        "            logging.warning(\"فینگرپرینت در متادیتای WEBP یافت نشد.\")\n",
        "\n",
        "        else:\n",
        "            logging.error(\"فرمت تصویر پشتیبانی نمی‌شود.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"خطا در استخراج فینگرپرینت از متادیتا: {e}\")\n",
        "        return None\n",
        "\n",
        "# مثال استفاده:\n",
        "# fingerprint = extract_fingerprint_from_image(\"path/to/image.jpg\")\n",
        "# if fingerprint:\n",
        "#     parsed_data = parse_image_fingerprint(fingerprint)\n",
        "#     print(parsed_data)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"🌍 اجرا شده در: {public_url}\")\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install piexif\n"
      ],
      "metadata": {
        "id": "V7iE92SQE1X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU1f5YCwmQhu"
      },
      "outputs": [],
      "source": [
        "import flask\n",
        "import pyngrok\n",
        "import numpy\n",
        "import faiss\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import timm\n",
        "import tensorflow_hub\n",
        "\n",
        "print(\"Flask:\", flask.__version__)\n",
        "print(\"Pyngrok:\", pyngrok.__version__)\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"FAISS:\", faiss.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Timm:\", timm.__version__)\n",
        "print(\"TensorFlow Hub:\", tensorflow_hub.__version__)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6I+fJzzLYrOKbwoiPjt3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}