{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrdadrashidian/CG-Ecosystem/blob/master/Media_Process_Unit_with_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TqTw8AZd8379",
        "outputId": "b57c9785-e219-4bf0-ecfd-e89b7b78878d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting Flask-SQLAlchemy\n",
            "  Downloading flask_sqlalchemy-3.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: flask>=2.2.5 in /usr/local/lib/python3.11/dist-packages (from Flask-SQLAlchemy) (3.1.0)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.16 in /usr/local/lib/python3.11/dist-packages (from Flask-SQLAlchemy) (2.0.38)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.2.5->Flask-SQLAlchemy) (1.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=2.0.16->Flask-SQLAlchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=2.0.16->Flask-SQLAlchemy) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask>=2.2.5->Flask-SQLAlchemy) (3.0.2)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_sqlalchemy-3.1.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: psycopg2-binary, Flask-SQLAlchemy\n",
            "Successfully installed Flask-SQLAlchemy-3.1.1 psycopg2-binary-2.9.10\n",
            "Collecting redis\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting Flask-Redis\n",
            "  Downloading flask_redis-0.4.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from Flask-Redis) (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->Flask-Redis) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->Flask-Redis) (3.0.2)\n",
            "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_redis-0.4.0-py2.py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: redis, Flask-Redis\n",
            "Successfully installed Flask-Redis-0.4.0 redis-5.2.1\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, imagehash\n",
            "Successfully installed PyWavelets-1.8.0 imagehash-4.3.2\n",
            "Collecting nsfw-detector\n",
            "  Downloading nsfw_detector-1.1.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from nsfw-detector) (11.1.0)\n",
            "Collecting tensorflow-hub==0.7.0 (from nsfw-detector)\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0->nsfw-detector) (4.25.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.1.0->nsfw-detector) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->nsfw-detector) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.1.0->nsfw-detector) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.1.0->nsfw-detector) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.1.0->nsfw-detector) (0.1.2)\n",
            "Downloading nsfw_detector-1.1.1-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-hub, nsfw-detector\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.16.1\n",
            "    Uninstalling tensorflow-hub-0.16.1:\n",
            "      Successfully uninstalled tensorflow-hub-0.16.1\n",
            "Successfully installed nsfw-detector-1.1.1 tensorflow-hub-0.7.0\n",
            "Collecting piexif\n",
            "  Downloading piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: piexif\n",
            "Successfully installed piexif-1.1.3\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.76-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.76-py3-none-any.whl (915 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m915.2/915.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.76 ultralytics-thop-2.0.14\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-hub==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (4.25.6)\n",
            "Collecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7b168f27a0d441798e87a5762708e97f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.70.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install Flask\n",
        "!pip install faiss-cpu\n",
        "!pip install opencv-python\n",
        "!pip install numpy\n",
        "!pip install psycopg2-binary Flask-SQLAlchemy\n",
        "!pip install redis Flask-Redis\n",
        "!pip install pyngrok\n",
        "!pip install pillow\n",
        "!pip install imagehash\n",
        "!pip install nsfw-detector\n",
        "!pip install piexif\n",
        "!pip install ultralytics\n",
        "!pip install torch torchvision\n",
        "!pip install numpy opencv-python\n",
        "!pip install torch torchvision\n",
        "!pip install numpy opencv-python\n",
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow-hub==0.7.0\n",
        "!pip install protobuf==3.20.*\n",
        "!pip install tensorflow==2.14.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow-hub==0.7.0\n",
        "!pip install protobuf==3.20.*\n",
        "!pip install tensorflow==2.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvCX6zFasOrO",
        "outputId": "90af7f94-8f61-4a85-87b5-3e31baa2cacd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-hub==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub==0.7.0) (3.20.3)\n",
            "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
            "Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.11/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n222hxZK9n8P",
        "outputId": "1cbe9443-eb81-4c52-d117-ea0db5ef2451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /mobilenet_v2_140_224.1.zip\n",
            "   creating: nsfw_model/mobilenet_v2_140_224/\n",
            "   creating: nsfw_model/mobilenet_v2_140_224/assets/\n",
            " extracting: nsfw_model/mobilenet_v2_140_224/class_labels.txt  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/frozen_graph.pb  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.h5  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.pb  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model.tflite  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/saved_model_weights.h5  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/training_results.txt  \n",
            "   creating: nsfw_model/mobilenet_v2_140_224/variables/\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.data-00000-of-00002  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.data-00001-of-00002  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/variables/variables.index  \n",
            "   creating: nsfw_model/mobilenet_v2_140_224/web_model/\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard1of5.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard2of5.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard3of5.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard4of5.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/group1-shard5of5.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model/model.json  \n",
            "   creating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/\n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard1of2.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/group1-shard2of2.bin  \n",
            "  inflating: nsfw_model/mobilenet_v2_140_224/web_model_quantized/model.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip /mobilenet_v2_140_224.1.zip -d nsfw_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_favr6vXzui",
        "outputId": "d0996030-cc3d-4402-b85b-c29ff64d1a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ مدل NSFW با موفقیت بارگذاری شد!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "nsfw_model = tf.saved_model.load(model_path)\n",
        "\n",
        "print(\"✅ مدل NSFW با موفقیت بارگذاری شد!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAsQHHwaUstC",
        "outputId": "d6270984-129d-48c4-a556-41f64b9ed69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 محتویات پوشه مدل: ['frozen_graph.pb', 'class_labels.txt', 'assets', 'saved_model.pb', 'saved_model_weights.h5', 'saved_model.h5', 'web_model_quantized', 'variables', 'web_model', 'saved_model.tflite', 'training_results.txt']\n",
            "📂 محتویات web_model_quantized: ['model.json', 'group1-shard2of2.bin', 'group1-shard1of2.bin']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_root = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "print(\"📂 محتویات پوشه مدل:\", os.listdir(model_root))\n",
        "\n",
        "web_model_path = os.path.join(model_root, \"web_model_quantized\")\n",
        "if os.path.exists(web_model_path):\n",
        "    print(\"📂 محتویات web_model_quantized:\", os.listdir(web_model_path))\n",
        "else:\n",
        "    print(\"❌ پوشه web_model_quantized وجود ندارد!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G_QQWu_9osE",
        "outputId": "0e324893-df9d-4f9e-d75b-3231d37cece8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ فایل مدل پیدا شد!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224/saved_model.h5\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ فایل مدل پیدا شد!\")\n",
        "else:\n",
        "    print(\"❌ فایل مدل در مسیر مشخص‌شده وجود ندارد.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jazZeG2Mtb0O",
        "outputId": "7d660d19-3848-4e12-b95b-65da72ae8232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "postgresql is already the newest version (14+238).\n",
            "postgresql-contrib is already the newest version (14+238).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install postgresql postgresql-contrib\n",
        "!service postgresql start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1oKyW0ttu4n",
        "outputId": "62ddb161-2401-45c1-ba7f-2487e4930560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE ROLE\n",
            "CREATE DATABASE\n"
          ]
        }
      ],
      "source": [
        "!sudo -u postgres psql -c \"CREATE USER myuser WITH PASSWORD 'mypassword';\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE mydb OWNER myuser;\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBdcXn4JLA49",
        "outputId": "227626f4-aa8b-4614-d56d-50767501625d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tee: /etc/postgresql/12/main/pg_hba.conf: No such file or directory\n",
            "host all all 127.0.0.1/32 md5\n",
            "tee: /etc/postgresql/12/main/pg_hba.conf: No such file or directory\n",
            "host all all ::1/128 md5\n"
          ]
        }
      ],
      "source": [
        "!echo \"host all all 127.0.0.1/32 md5\" | sudo tee -a /etc/postgresql/12/main/pg_hba.conf\n",
        "!echo \"host all all ::1/128 md5\" | sudo tee -a /etc/postgresql/12/main/pg_hba.conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VZqtoLx8mte",
        "outputId": "6c81fc49-c456-4dd7-dd18-b613bcbae833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0abde2d6a186>:29: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-2-19 Python-3.11.11 torch-2.5.1+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 اجرا شده در: NgrokTunnel: \"https://c4c9-35-229-196-90.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Feb/2025 14:53:51] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Feb/2025 14:53:51] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Feb/2025 14:53:51] \"GET /get_media/text HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Feb/2025 14:53:54] \"GET /get_media/image HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Feb/2025 14:53:56] \"GET /get_media/video HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "!pkill -9 ngrok\n",
        "from pyngrok import ngrok\n",
        "import io\n",
        "import os\n",
        "import datetime\n",
        "import binascii\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch\n",
        "import cv2\n",
        "import tensorflow.compat.v1 as tf\n",
        "import timm\n",
        "import logging\n",
        "import uuid  # برای تولید نام یکتا\n",
        "import piexif\n",
        "from flask import Flask, request, jsonify, render_template_string, send_from_directory\n",
        "from PIL import Image, PngImagePlugin\n",
        "from sqlalchemy import create_engine, Column, Integer, String, LargeBinary, Text\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# پیکربندی logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# ============================\n",
        "# تنظیمات دیتابیس\n",
        "# ============================\n",
        "Base = declarative_base()\n",
        "\n",
        "class MediaEmbedding(Base):\n",
        "    __tablename__ = \"media_embeddings\"\n",
        "    id = Column(Integer, primary_key=True, index=True)\n",
        "    filename = Column(String, unique=True, index=True)\n",
        "    media_type = Column(String, default=\"image\")  # image, video, text, audio\n",
        "    file_data = Column(LargeBinary)  # داده‌های فایل (باینری)\n",
        "    embedding = Column(LargeBinary)\n",
        "    nudity_score = Column(String)\n",
        "    hashtags = Column(Text)\n",
        "    fingerprint = Column(String)\n",
        "\n",
        "DATABASE_URL = \"postgresql://myuser:mypassword@localhost/mydb\"\n",
        "engine = create_engine(DATABASE_URL)\n",
        "SessionLocal = sessionmaker(bind=engine)\n",
        "Base.metadata.create_all(engine)\n",
        "\n",
        "# ============================\n",
        "# تنظیمات اولیه\n",
        "# ============================\n",
        "UPLOAD_FOLDER = 'static/uploads'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "NGROK_TOKEN = \"2t08AjrgjGJnUDUrLjg6fozszuO_3SJM8YDbbBr6xiRoJupNm\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# بارگذاری مدل YOLOv5 پیش‌ساخته\n",
        "Yolo_Model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# تنظیم FAISS\n",
        "D = 512\n",
        "index = faiss.IndexFlatL2(D)\n",
        "index_path = \"faiss.index\"\n",
        "if os.path.exists(index_path):\n",
        "    index = faiss.read_index(index_path)\n",
        "\n",
        "# تنظیم مدل ویژگی‌برداری\n",
        "feature_extractor = timm.create_model(\"tf_efficientnet_b0\", pretrained=True, num_classes=0)\n",
        "feature_extractor.eval()\n",
        "\n",
        "# ایجاد اپلیکیشن Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ============================\n",
        "# تنظیم مدل NSFW\n",
        "# ============================\n",
        "tf.disable_eager_execution()\n",
        "session_tf = tf.Session()\n",
        "session_tf.run(tf.global_variables_initializer())\n",
        "model_path = \"/content/nsfw_model/mobilenet_v2_140_224\"\n",
        "with session_tf.as_default():\n",
        "    with session_tf.graph.as_default():\n",
        "        nsfw_model = tf.saved_model.loader.load(session_tf, [tf.saved_model.SERVING], model_path)\n",
        "        infer = nsfw_model.signature_def[\"serving_default\"]\n",
        "        input_tensor_name = infer.inputs[\"input\"].name\n",
        "        output_tensor_name = infer.outputs[\"prediction\"].name\n",
        "        input_tensor = session_tf.graph.get_tensor_by_name(input_tensor_name)\n",
        "        output_tensor = session_tf.graph.get_tensor_by_name(output_tensor_name)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# توابع پردازش محتوا (فعلاً برای نوع \"image\")\n",
        "# ------------------------------------------------\n",
        "def detect_nudity(file_path, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"Nudity detection is not implemented for media type: {}\".format(media_type))\n",
        "        return {}\n",
        "    with session_tf.as_default():\n",
        "        with session_tf.graph.as_default():\n",
        "            img = Image.open(file_path).convert(\"RGB\").resize((224, 224))\n",
        "            img_array = np.array(img).astype(np.float32) / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            result = session_tf.run(output_tensor, feed_dict={input_tensor: img_array})\n",
        "            return {\"sexy\": f\"{round(float(result[0][4]) * 100, 2)}%\", \"porn\": f\"{round(float(result[0][3]) * 100, 2)}%\"}\n",
        "\n",
        "def generate_embedding(file_path, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"Embedding extraction is not implemented for media type: {}\".format(media_type))\n",
        "        return None\n",
        "    try:\n",
        "        img = Image.open(file_path).convert(\"RGB\")\n",
        "        img = np.array(img).astype('float32') / 255.0\n",
        "        img = torch.tensor(img).permute(2, 0, 1).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            embedding = feature_extractor(img).numpy()\n",
        "        embedding = embedding.reshape(1, -1)\n",
        "        if embedding.shape[1] > D:\n",
        "            embedding = embedding[:, :D]\n",
        "        elif embedding.shape[1] < D:\n",
        "            padding = np.zeros((1, D - embedding.shape[1]), dtype=embedding.dtype)\n",
        "            embedding = np.concatenate([embedding, padding], axis=1)\n",
        "        if not isinstance(embedding, np.ndarray):\n",
        "            logging.error(f\"❌ خروجی embedding مقدار نامعتبری دارد: {type(embedding)}\")\n",
        "            return None\n",
        "        logging.info(f\"✅ استخراج embedding موفقیت‌آمیز بود. شکل نهایی: {embedding.shape}\")\n",
        "        return embedding.astype('float32')\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در استخراج embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_embeddings_from_db(media_type):\n",
        "    session_db = SessionLocal()\n",
        "    media_entries = session_db.query(MediaEmbedding).filter_by(media_type=media_type).all()\n",
        "    session_db.close()\n",
        "    embeddings = [np.frombuffer(entry.embedding, dtype=np.float32) for entry in media_entries]\n",
        "    filenames = [entry.filename for entry in media_entries]\n",
        "    hashtags_list = [entry.hashtags for entry in media_entries]\n",
        "    if len(embeddings) == 0:\n",
        "        return np.empty((0, D), dtype=np.float32), filenames, hashtags_list\n",
        "    return np.vstack(embeddings), filenames, hashtags_list\n",
        "\n",
        "def check_duplicate(filename, embedding, media_type, sim_threshold=0.9):\n",
        "    session_db = SessionLocal()\n",
        "    try:\n",
        "        duplicate_name = session_db.query(MediaEmbedding).filter_by(filename=filename, media_type=media_type).first()\n",
        "        if duplicate_name:\n",
        "            session_db.close()\n",
        "            return {\n",
        "                \"duplicate\": True,\n",
        "                \"reason\": \"filename\",\n",
        "                \"message\": f\"فایل تکراری است: {filename}\"\n",
        "            }\n",
        "        embeddings_db, filenames, _ = load_embeddings_from_db(media_type)\n",
        "        if embeddings_db.shape[0] == 0:\n",
        "            session_db.close()\n",
        "            return {\"duplicate\": False}\n",
        "        normalized_query = embedding / np.linalg.norm(embedding)\n",
        "        norms = np.linalg.norm(embeddings_db, axis=1, keepdims=True)\n",
        "        norms[norms == 0] = 1\n",
        "        normalized_embeddings = embeddings_db / norms\n",
        "        cosine_similarities = np.dot(normalized_query, normalized_embeddings.T)[0]\n",
        "        similar_indices = np.where(cosine_similarities >= sim_threshold)[0]\n",
        "        if similar_indices.size > 0:\n",
        "            similar_files = [filenames[i] for i in similar_indices]\n",
        "            session_db.close()\n",
        "            return {\n",
        "                \"duplicate\": True,\n",
        "                \"reason\": \"embedding\",\n",
        "                \"message\": f\"فایل تکراری است: محتوا با مشابهت بالای 90 درصد ({', '.join(similar_files)})\"\n",
        "            }\n",
        "        session_db.close()\n",
        "        return {\"duplicate\": False}\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در بررسی تکراری بودن محتوا: {e}\")\n",
        "        session_db.close()\n",
        "        return {\"duplicate\": False}\n",
        "\n",
        "def save_to_database(filename, file_path, embedding, nudity_score, hashtags, fingerprint, media_type):\n",
        "    try:\n",
        "        session_db = SessionLocal()\n",
        "        existing_entry = session_db.query(MediaEmbedding).filter_by(filename=filename, media_type=media_type).first()\n",
        "        if existing_entry:\n",
        "            logging.warning(f\"⚠️ فایل {filename} از قبل در دیتابیس وجود دارد.\")\n",
        "            session_db.close()\n",
        "            return False\n",
        "        embedding_bytes = embedding.tobytes()\n",
        "        with open(file_path, \"rb\") as file_obj:\n",
        "            file_data = file_obj.read()\n",
        "        new_entry = MediaEmbedding(\n",
        "            filename=filename,\n",
        "            media_type=media_type,\n",
        "            file_data=file_data,\n",
        "            embedding=embedding_bytes,\n",
        "            nudity_score=str(nudity_score),\n",
        "            hashtags=\",\".join(hashtags) if hashtags else \"\",\n",
        "            fingerprint=fingerprint\n",
        "        )\n",
        "        session_db.add(new_entry)\n",
        "        session_db.commit()\n",
        "        logging.info(f\"✅ {media_type} {filename} با موفقیت در دیتابیس ذخیره شد.\")\n",
        "        session_db.close()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        session_db.rollback()\n",
        "        logging.error(f\"❌ خطا در ذخیره اطلاعات در دیتابیس: {e}\")\n",
        "        session_db.close()\n",
        "        return False\n",
        "\n",
        "def allowed_file(filename, media_type):\n",
        "    if media_type == \"image\":\n",
        "        return filename.lower().endswith(('png', 'jpg', 'jpeg', 'webp'))\n",
        "    elif media_type == \"video\":\n",
        "        return filename.lower().endswith(('mp4', 'avi', 'mov'))\n",
        "    elif media_type == \"text\":\n",
        "        return filename.lower().endswith(('txt', 'doc', 'docx', 'pdf'))\n",
        "    elif media_type == \"audio\":\n",
        "        return filename.lower().endswith(('mp3', 'wav', 'aac'))\n",
        "    else:\n",
        "        logging.error(\"Unsupported media type: {}\".format(media_type))\n",
        "        return False\n",
        "\n",
        "def generate_fingerprint(file_path, username, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"Fingerprint generation is not implemented for media type: {}\".format(media_type))\n",
        "        return None\n",
        "    try:\n",
        "        now_str = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S%f\")\n",
        "        now_hex = now_str.encode('utf-8').hex()\n",
        "        image = Image.open(file_path).convert(\"L\")\n",
        "        image = image.resize((9, 8), resample=Image.LANCZOS)\n",
        "        pixels = list(image.getdata())\n",
        "        difference = []\n",
        "        for row in range(8):\n",
        "            for col in range(8):\n",
        "                left_pixel = pixels[row * 9 + col]\n",
        "                right_pixel = pixels[row * 9 + col + 1]\n",
        "                difference.append(1 if left_pixel > right_pixel else 0)\n",
        "        hash_val = 0\n",
        "        for bit in difference:\n",
        "            hash_val = (hash_val << 1) | bit\n",
        "        image_fingerprint = hex(hash_val)[2:].rjust(16, '0')\n",
        "        username_hex = username.encode('utf-8').hex()\n",
        "        combined_fingerprint = image_fingerprint + \"-\" + username_hex + \"-\" + now_hex\n",
        "        return combined_fingerprint\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در تولید فینگرپرینت: {e}\")\n",
        "        return None\n",
        "\n",
        "def embed_fingerprint(file_path, output_path, fingerprint, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"Embedding fingerprint is not implemented for media type: {}\".format(media_type))\n",
        "        return False\n",
        "    try:\n",
        "        image = Image.open(file_path)\n",
        "        ext = os.path.splitext(file_path)[1].lower()\n",
        "        if ext in [\".jpeg\", \".jpg\"]:\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "            else:\n",
        "                exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}, \"thumbnail\": None}\n",
        "            exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = fingerprint.encode(\"utf-8\")\n",
        "            exif_bytes = piexif.dump(exif_dict)\n",
        "            image.save(output_path, \"jpeg\", exif=exif_bytes)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل JPEG/JPG درج شد.\")\n",
        "        elif ext == \".png\":\n",
        "            png_info = PngImagePlugin.PngInfo()\n",
        "            png_info.add_text(\"Fingerprint\", fingerprint)\n",
        "            image.save(output_path, \"png\", pnginfo=png_info)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل PNG درج شد.\")\n",
        "        elif ext == \".bmp\":\n",
        "            if not hasattr(image, \"info\"):\n",
        "                image.info = {}\n",
        "            image.info[\"comment\"] = fingerprint\n",
        "            image.save(output_path, \"bmp\")\n",
        "            logging.info(\"فینگرپرینت (به صورت comment) در فایل BMP درج شد (توجه: پشتیبانی محدود).\")\n",
        "        elif ext == \".webp\":\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "            else:\n",
        "                exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}, \"thumbnail\": None}\n",
        "            exif_dict[\"Exif\"][piexif.ExifIFD.UserComment] = fingerprint.encode(\"utf-8\")\n",
        "            exif_bytes = piexif.dump(exif_dict)\n",
        "            image.save(output_path, \"WEBP\", exif=exif_bytes)\n",
        "            logging.info(\"فینگرپرینت به عنوان متادیتا در فایل WEBP درج شد.\")\n",
        "        else:\n",
        "            logging.error(\"فرمت فایل پشتیبانی نمی‌شود.\")\n",
        "            return False\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logging.error(f\"خطا در درج فینگرپرینت در متادیتا: {e}\")\n",
        "        return False\n",
        "\n",
        "def parse_fingerprint(fingerprint):\n",
        "    try:\n",
        "        parts = fingerprint.split(\"-\")\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(\"ساختار فینگرپرینت نامعتبر است.\")\n",
        "        image_fingerprint, username_hex, timestamp_hex = parts\n",
        "        username = binascii.unhexlify(username_hex).decode('utf-8')\n",
        "        timestamp_str = binascii.unhexlify(timestamp_hex).decode('utf-8')\n",
        "        timestamp = datetime.datetime.strptime(timestamp_str, \"%Y%m%d%H%M%S%f\")\n",
        "        return {\n",
        "            \"image_fingerprint\": image_fingerprint,\n",
        "            \"username\": username,\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در تفسیر فینگرپرینت: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_fingerprint(file_path):\n",
        "    try:\n",
        "        image = Image.open(file_path)\n",
        "        ext = os.path.splitext(file_path)[1].lower()\n",
        "        if ext in [\".jpeg\", \".jpg\"]:\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "                if piexif.ExifIFD.UserComment in exif_dict[\"Exif\"]:\n",
        "                    fingerprint_bytes = exif_dict[\"Exif\"][piexif.ExifIFD.UserComment]\n",
        "                    fingerprint = fingerprint_bytes.decode(\"utf-8\")\n",
        "                    return fingerprint\n",
        "            logging.warning(\"فینگرپرینت در متادیتای EXIF فایل JPEG/JPG یافت نشد.\")\n",
        "        elif ext == \".png\":\n",
        "            png_info = image.info\n",
        "            if \"Fingerprint\" in png_info:\n",
        "                return png_info[\"Fingerprint\"]\n",
        "            logging.warning(\"فینگرپرینت در متادیتای PNG یافت نشد.\")\n",
        "        elif ext == \".bmp\":\n",
        "            if \"comment\" in image.info:\n",
        "                return image.info[\"comment\"]\n",
        "            logging.warning(\"فینگرپرینت در متادیتای BMP یافت نشد.\")\n",
        "        elif ext == \".webp\":\n",
        "            if \"exif\" in image.info:\n",
        "                exif_dict = piexif.load(image.info[\"exif\"])\n",
        "                if piexif.ExifIFD.UserComment in exif_dict[\"Exif\"]:\n",
        "                    fingerprint_bytes = exif_dict[\"Exif\"][piexif.ExifIFD.UserComment]\n",
        "                    fingerprint = fingerprint_bytes.decode(\"utf-8\")\n",
        "                    return fingerprint\n",
        "            logging.warning(\"فینگرپرینت در متادیتای WEBP یافت نشد.\")\n",
        "        else:\n",
        "            logging.error(\"فرمت فایل پشتیبانی نمی‌شود.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logging.error(f\"خطا در استخراج فینگرپرینت از متادیتا: {e}\")\n",
        "        return None\n",
        "\n",
        "def RGA(file_path, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"RGA is not implemented for media type: {}\".format(media_type))\n",
        "        return {\"sexy\": \"0%\", \"porn\": \"0%\", \"category\": \"N/A\"}\n",
        "    with session_tf.as_default():\n",
        "        with session_tf.graph.as_default():\n",
        "            img = Image.open(file_path).convert(\"RGB\").resize((224, 224))\n",
        "            img_array = np.array(img).astype(np.float32) / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            result = session_tf.run(output_tensor, feed_dict={input_tensor: img_array})\n",
        "            sexy_score = round(float(result[0][4]) * 100, 2)\n",
        "            porn_score = round(float(result[0][3]) * 100, 2)\n",
        "            max_score = max(sexy_score, porn_score)\n",
        "            if max_score >= 75:\n",
        "                category = \"R\"\n",
        "            elif 40 <= max_score < 75:\n",
        "                category = \"A\"\n",
        "            else:\n",
        "                category = \"G\"\n",
        "            return {\"sexy\": f\"{sexy_score}%\", \"porn\": f\"{porn_score}%\", \"category\": category}\n",
        "\n",
        "def run_yolo_detection(file_path, media_type):\n",
        "    if media_type != \"image\":\n",
        "        logging.error(\"YOLO detection is not implemented for media type: {}\".format(media_type))\n",
        "        return []\n",
        "    model = YOLO(\"yolov8s.pt\")\n",
        "    results = model(file_path)\n",
        "    entities = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            class_id = int(box.cls[0])\n",
        "            label = model.names[class_id]\n",
        "            entities.append(label)\n",
        "    return entities\n",
        "\n",
        "def detect_entities(file_path, media_type):\n",
        "    yolo_results = run_yolo_detection(file_path, media_type)\n",
        "    logging.info(f\"YOLO results: {yolo_results}\")\n",
        "    if not yolo_results:\n",
        "        return []\n",
        "    return [f\"#{entity}\" for entity in set(yolo_results)]\n",
        "\n",
        "# --------------------------\n",
        "# تابع توصیه گر (بر اساس محتوای موجود در دیتابیس)\n",
        "# --------------------------\n",
        "def recommend_content(input_filename, media_type, top_n=10):\n",
        "    try:\n",
        "        session_db = SessionLocal()\n",
        "        input_record = session_db.query(MediaEmbedding).filter_by(filename=input_filename, media_type=media_type).first()\n",
        "        session_db.close()\n",
        "        if not input_record:\n",
        "            logging.error(f\"❌ محتوای ورودی با نام {input_filename} در دیتابیس یافت نشد.\")\n",
        "            return []\n",
        "        input_embedding = np.frombuffer(input_record.embedding, dtype=np.float32).reshape(1, -1)\n",
        "        input_hashtags = input_record.hashtags.split(\",\") if input_record.hashtags else []\n",
        "        embeddings_db, filenames, hashtags_list = load_embeddings_from_db(media_type)\n",
        "        if embeddings_db.shape[0] == 0:\n",
        "            logging.warning(\"❌ هیچ محتوایی در دیتابیس موجود نیست.\")\n",
        "            return []\n",
        "        candidate_embeddings = []\n",
        "        candidate_filenames = []\n",
        "        candidate_hashtags_list = []\n",
        "        for i, fname in enumerate(filenames):\n",
        "            if fname == input_filename:\n",
        "                continue\n",
        "            candidate_embeddings.append(embeddings_db[i])\n",
        "            candidate_filenames.append(fname)\n",
        "            candidate_hashtags_list.append(hashtags_list[i].split(\",\") if hashtags_list[i] else [])\n",
        "        if len(candidate_embeddings) == 0:\n",
        "            logging.warning(\"تنها محتوای موجود در دیتابیس، محتوای ورودی است.\")\n",
        "            return []\n",
        "        candidate_embeddings = np.vstack(candidate_embeddings)\n",
        "        from sklearn.cluster import KMeans\n",
        "        num_candidates = candidate_embeddings.shape[0]\n",
        "        k = min(top_n, num_candidates) if num_candidates > 0 else 1\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(candidate_embeddings)\n",
        "        input_cluster = kmeans.predict(input_embedding)[0]\n",
        "        recommendations = []\n",
        "        norm_input = input_embedding / np.linalg.norm(input_embedding)\n",
        "        for idx in [i for i, label in enumerate(kmeans.labels_) if label == input_cluster]:\n",
        "            candidate_emb = candidate_embeddings[idx].reshape(1, -1)\n",
        "            norm_candidate = candidate_emb / np.linalg.norm(candidate_emb)\n",
        "            cosine_sim = np.dot(norm_input, norm_candidate.T)[0][0]\n",
        "            common_tags = set(input_hashtags).intersection(set(candidate_hashtags_list[idx]))\n",
        "            hashtag_bonus = 0.1 * len(common_tags)\n",
        "            total_score = cosine_sim + hashtag_bonus\n",
        "            recommendations.append({\n",
        "                \"filename\": candidate_filenames[idx],\n",
        "                \"cosine_similarity\": round(cosine_sim * 100, 2),\n",
        "                \"common_hashtags\": list(common_tags),\n",
        "                \"total_score\": round(total_score, 4)\n",
        "            })\n",
        "        recommendations.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
        "        if len(recommendations) < top_n:\n",
        "            other_indices = [i for i in range(num_candidates) if i not in [i for i, label in enumerate(kmeans.labels_) if label == input_cluster]]\n",
        "            other_recommendations = []\n",
        "            for idx in other_indices:\n",
        "                candidate_emb = candidate_embeddings[idx].reshape(1, -1)\n",
        "                norm_candidate = candidate_emb / np.linalg.norm(candidate_emb)\n",
        "                cosine_sim = np.dot(norm_input, norm_candidate.T)[0][0]\n",
        "                common_tags = set(input_hashtags).intersection(set(candidate_hashtags_list[idx]))\n",
        "                hashtag_bonus = 0.1 * len(common_tags)\n",
        "                total_score = cosine_sim + hashtag_bonus\n",
        "                other_recommendations.append({\n",
        "                    \"filename\": candidate_filenames[idx],\n",
        "                    \"cosine_similarity\": round(cosine_sim * 100, 2),\n",
        "                    \"common_hashtags\": list(common_tags),\n",
        "                    \"total_score\": round(total_score, 4)\n",
        "                })\n",
        "            other_recommendations.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
        "            recommendations.extend(other_recommendations)\n",
        "        return recommendations[:top_n]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"❌ خطا در تابع توصیه گر: {e}\")\n",
        "        return []\n",
        "\n",
        "# --------------------------\n",
        "# صفحه HTML اصلی با تب‌ها، مدال‌ها (آپلود، جستجو و توصیه) و progress bar\n",
        "# --------------------------\n",
        "html_page = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"fa\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <title>گالری محتوا</title>\n",
        "  <style>\n",
        "    body {\n",
        "      font-family: 'Tahoma', sans-serif;\n",
        "      background: #f4f6f8;\n",
        "      margin: 0;\n",
        "      padding: 0;\n",
        "      direction: rtl;\n",
        "    }\n",
        "    .header {\n",
        "      background: #394263;\n",
        "      color: #fff;\n",
        "      padding: 15px;\n",
        "      display: flex;\n",
        "      justify-content: space-between;\n",
        "      align-items: center;\n",
        "    }\n",
        "    .header h1 { margin: 0; }\n",
        "    .header .actions button {\n",
        "      background: #5a6ea8;\n",
        "      border: none;\n",
        "      color: #fff;\n",
        "      padding: 8px 12px;\n",
        "      margin-left: 5px;\n",
        "      cursor: pointer;\n",
        "      border-radius: 4px;\n",
        "    }\n",
        "    .tabs {\n",
        "      display: flex;\n",
        "      background: #fff;\n",
        "      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .tab {\n",
        "      flex: 1;\n",
        "      text-align: center;\n",
        "      padding: 12px;\n",
        "      cursor: pointer;\n",
        "      border-bottom: 2px solid transparent;\n",
        "    }\n",
        "    .tab.active {\n",
        "      background: #e2e6ea;\n",
        "      border-bottom: 2px solid #394263;\n",
        "      font-weight: bold;\n",
        "    }\n",
        "    .content-area {\n",
        "      padding: 20px;\n",
        "    }\n",
        "    .media-card {\n",
        "      background: #fff;\n",
        "      border: 1px solid #ddd;\n",
        "      border-radius: 5px;\n",
        "      margin-bottom: 15px;\n",
        "      overflow: hidden;\n",
        "      display: flex;\n",
        "      box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
        "    }\n",
        "    .media-thumb {\n",
        "      flex-shrink: 0;\n",
        "      width: 120px;\n",
        "      height: 120px;\n",
        "      background: #ccc;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "    }\n",
        "    .media-thumb img, .media-thumb video, .media-thumb audio {\n",
        "      max-width: 100%;\n",
        "      max-height: 100%;\n",
        "    }\n",
        "    .text-thumbnail {\n",
        "      font-size: 24px;\n",
        "      color: #394263;\n",
        "    }\n",
        "    .media-info {\n",
        "      padding: 10px;\n",
        "      flex-grow: 1;\n",
        "    }\n",
        "    .media-info h5 {\n",
        "      margin: 0 0 5px 0;\n",
        "      color: #394263;\n",
        "    }\n",
        "    .media-info p {\n",
        "      margin: 3px 0;\n",
        "      font-size: 14px;\n",
        "      color: #555;\n",
        "    }\n",
        "    /* تگ RGA */\n",
        "    .rga-tag {\n",
        "      font-weight: bold;\n",
        "      padding: 2px 6px;\n",
        "      border-radius: 4px;\n",
        "      color: white;\n",
        "    }\n",
        "    .rga-r { background-color: red; }\n",
        "    .rga-g { background-color: green; }\n",
        "    .rga-a { background-color: orange; }\n",
        "    /* مدال‌ها */\n",
        "    .modal {\n",
        "      display: none;\n",
        "      position: fixed;\n",
        "      z-index: 100;\n",
        "      left: 0;\n",
        "      top: 0;\n",
        "      width: 100%;\n",
        "      height: 100%;\n",
        "      overflow: auto;\n",
        "      background: rgba(0,0,0,0.5);\n",
        "    }\n",
        "    .modal-content {\n",
        "      background: #fff;\n",
        "      margin: 10% auto;\n",
        "      padding: 20px;\n",
        "      border-radius: 8px;\n",
        "      width: 90%;\n",
        "      max-width: 500px;\n",
        "      position: relative;\n",
        "    }\n",
        "    .close {\n",
        "      color: #aaa;\n",
        "      position: absolute;\n",
        "      top: 10px;\n",
        "      left: 10px;\n",
        "      font-size: 28px;\n",
        "      font-weight: bold;\n",
        "      cursor: pointer;\n",
        "    }\n",
        "    .drag-drop {\n",
        "      border: 2px dashed #394263;\n",
        "      border-radius: 5px;\n",
        "      padding: 30px;\n",
        "      text-align: center;\n",
        "      color: #394263;\n",
        "      margin-bottom: 15px;\n",
        "    }\n",
        "    input[type=\"file\"] {\n",
        "      display: none;\n",
        "    }\n",
        "    .btn {\n",
        "      background: #394263;\n",
        "      color: #fff;\n",
        "      border: none;\n",
        "      padding: 10px 15px;\n",
        "      cursor: pointer;\n",
        "      border-radius: 4px;\n",
        "    }\n",
        "    /* progress bar */\n",
        "    .progress-container {\n",
        "      width: 100%;\n",
        "      background-color: #ddd;\n",
        "      border-radius: 4px;\n",
        "      margin-top: 10px;\n",
        "      display: none;\n",
        "    }\n",
        "    .progress-bar {\n",
        "      width: 0%;\n",
        "      height: 20px;\n",
        "      background-color: #394263;\n",
        "      border-radius: 4px;\n",
        "      text-align: center;\n",
        "      line-height: 20px;\n",
        "      color: white;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"header\">\n",
        "    <h1>گالری محتوا</h1>\n",
        "    <div class=\"actions\">\n",
        "      <button id=\"uploadBtn\">+</button>\n",
        "      <button id=\"searchBtn\">جستجو</button>\n",
        "      <button id=\"recommendBtn\">توصیه</button>\n",
        "    </div>\n",
        "  </div>\n",
        "  <div class=\"tabs\">\n",
        "    <div class=\"tab active\" data-media=\"text\">متن</div>\n",
        "    <div class=\"tab\" data-media=\"audio\">صوت</div>\n",
        "    <div class=\"tab\" data-media=\"image\">عکس</div>\n",
        "    <div class=\"tab\" data-media=\"video\">ویدیو</div>\n",
        "  </div>\n",
        "  <div class=\"content-area\" id=\"content-area\">\n",
        "    <!-- محتواها در اینجا بارگذاری می‌شوند -->\n",
        "  </div>\n",
        "\n",
        "  <!-- مدال آپلود -->\n",
        "  <div id=\"uploadModal\" class=\"modal\">\n",
        "    <div class=\"modal-content\">\n",
        "      <span class=\"close\" id=\"closeUpload\">&times;</span>\n",
        "      <h3>آپلود محتوا</h3>\n",
        "      <form id=\"uploadForm\" method=\"POST\" enctype=\"multipart/form-data\">\n",
        "        <div class=\"drag-drop\" id=\"uploadDrop\">\n",
        "          فایل خود را اینجا بکشید و رها کنید\n",
        "          <br>\n",
        "          یا کلیک کنید\n",
        "          <input type=\"file\" name=\"file\" id=\"uploadFile\">\n",
        "        </div>\n",
        "        <input type=\"hidden\" name=\"media_type\" value=\"image\">\n",
        "        <button type=\"submit\" class=\"btn\">ثبت محتوا</button>\n",
        "        <div id=\"uploadProgressContainer\" class=\"progress-container\">\n",
        "          <div id=\"uploadProgressBar\" class=\"progress-bar\">0%</div>\n",
        "        </div>\n",
        "        <div id=\"uploadMessage\"></div>\n",
        "      </form>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <!-- مدال جستجو -->\n",
        "  <div id=\"searchModal\" class=\"modal\">\n",
        "    <div class=\"modal-content\">\n",
        "      <span class=\"close\" id=\"closeSearch\">&times;</span>\n",
        "      <h3>جستجو در محتوا</h3>\n",
        "      <form id=\"searchForm\" method=\"POST\" action=\"/search\" enctype=\"multipart/form-data\">\n",
        "        <div class=\"drag-drop\" id=\"searchDrop\">\n",
        "          فایل خود را اینجا بکشید و رها کنید\n",
        "          <br>\n",
        "          یا کلیک کنید\n",
        "          <input type=\"file\" name=\"file\" id=\"searchFile\">\n",
        "        </div>\n",
        "        <button type=\"submit\" class=\"btn\">جستجو</button>\n",
        "        <div id=\"searchProgressContainer\" class=\"progress-container\">\n",
        "          <div id=\"searchProgressBar\" class=\"progress-bar\">0%</div>\n",
        "        </div>\n",
        "        <div id=\"searchMessage\"></div>\n",
        "      </form>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <!-- مدال توصیه -->\n",
        "  <div id=\"recommendModal\" class=\"modal\">\n",
        "    <div class=\"modal-content\">\n",
        "      <span class=\"close\" id=\"closeRecommend\">&times;</span>\n",
        "      <h3>توصیه محتوا</h3>\n",
        "      <form id=\"recommendForm\" method=\"POST\" action=\"/recommend\">\n",
        "        <label for=\"inputFilename\">انتخاب محتوا:</label>\n",
        "        <select name=\"inputFilename\" id=\"inputFilename\">\n",
        "          <!-- گزینه‌ها از طریق جاوا اسکریپت بارگذاری می‌شوند -->\n",
        "        </select>\n",
        "        <input type=\"hidden\" name=\"media_type\" id=\"recommendMediaType\" value=\"image\">\n",
        "        <button type=\"submit\" class=\"btn\">توصیه</button>\n",
        "        <div id=\"recommendProgressContainer\" class=\"progress-container\">\n",
        "          <div id=\"recommendProgressBar\" class=\"progress-bar\">0%</div>\n",
        "        </div>\n",
        "      </form>\n",
        "      <div id=\"recommendResults\"></div>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    function simulateProgress(progressBarId, progressContainerId, callback) {\n",
        "      const progressBar = document.getElementById(progressBarId);\n",
        "      const progressContainer = document.getElementById(progressContainerId);\n",
        "      progressContainer.style.display = \"block\";\n",
        "      let progress = 0;\n",
        "      const interval = setInterval(() => {\n",
        "        progress += Math.floor(Math.random() * 10) + 5;\n",
        "        if(progress >= 90){\n",
        "          progress = 90;\n",
        "          clearInterval(interval);\n",
        "        }\n",
        "        progressBar.style.width = progress + \"%\";\n",
        "        progressBar.textContent = progress + \"%\";\n",
        "      }, 200);\n",
        "      return function finish() {\n",
        "        clearInterval(interval);\n",
        "        progressBar.style.width = \"100%\";\n",
        "        progressBar.textContent = \"100%\";\n",
        "        setTimeout(() => { progressContainer.style.display = \"none\"; }, 500);\n",
        "        if(callback) callback();\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // مدیریت مدال‌ها\n",
        "    const uploadBtn = document.getElementById(\"uploadBtn\");\n",
        "    const uploadModal = document.getElementById(\"uploadModal\");\n",
        "    const closeUpload = document.getElementById(\"closeUpload\");\n",
        "    uploadBtn.addEventListener(\"click\", () => { uploadModal.style.display = \"block\"; });\n",
        "    closeUpload.addEventListener(\"click\", () => { uploadModal.style.display = \"none\"; });\n",
        "\n",
        "    const searchBtn = document.getElementById(\"searchBtn\");\n",
        "    const searchModal = document.getElementById(\"searchModal\");\n",
        "    const closeSearch = document.getElementById(\"closeSearch\");\n",
        "    searchBtn.addEventListener(\"click\", () => { searchModal.style.display = \"block\"; });\n",
        "    closeSearch.addEventListener(\"click\", () => { searchModal.style.display = \"none\"; });\n",
        "\n",
        "    const recommendBtn = document.getElementById(\"recommendBtn\");\n",
        "    const recommendModal = document.getElementById(\"recommendModal\");\n",
        "    const closeRecommend = document.getElementById(\"closeRecommend\");\n",
        "    recommendBtn.addEventListener(\"click\", () => {\n",
        "      const activeTab = document.querySelector(\".tab.active\").getAttribute(\"data-media\");\n",
        "      document.getElementById(\"recommendMediaType\").value = activeTab;\n",
        "      fetch(\"/get_media_list/\" + activeTab)\n",
        "        .then(response => response.json())\n",
        "        .then(data => {\n",
        "          const select = document.getElementById(\"inputFilename\");\n",
        "          select.innerHTML = \"\";\n",
        "          data.forEach(item => {\n",
        "             const option = document.createElement(\"option\");\n",
        "             option.value = item.filename;\n",
        "             option.textContent = item.filename;\n",
        "             select.appendChild(option);\n",
        "          });\n",
        "          recommendModal.style.display = \"block\";\n",
        "        });\n",
        "    });\n",
        "    closeRecommend.addEventListener(\"click\", () => { recommendModal.style.display = \"none\"; });\n",
        "\n",
        "    // Drag & Drop برای آپلود و جستجو\n",
        "    const uploadDrop = document.getElementById(\"uploadDrop\");\n",
        "    const uploadFile = document.getElementById(\"uploadFile\");\n",
        "    uploadDrop.addEventListener(\"click\", () => uploadFile.click());\n",
        "    uploadDrop.addEventListener(\"dragover\", (e) => { e.preventDefault(); uploadDrop.style.background = \"#e2e6ea\"; });\n",
        "    uploadDrop.addEventListener(\"dragleave\", (e) => { e.preventDefault(); uploadDrop.style.background = \"transparent\"; });\n",
        "    uploadDrop.addEventListener(\"drop\", (e) => { e.preventDefault(); uploadFile.files = e.dataTransfer.files; uploadDrop.style.background = \"transparent\"; });\n",
        "\n",
        "    const searchDrop = document.getElementById(\"searchDrop\");\n",
        "    const searchFile = document.getElementById(\"searchFile\");\n",
        "    searchDrop.addEventListener(\"click\", () => searchFile.click());\n",
        "    searchDrop.addEventListener(\"dragover\", (e) => { e.preventDefault(); searchDrop.style.background = \"#e2e6ea\"; });\n",
        "    searchDrop.addEventListener(\"dragleave\", (e) => { e.preventDefault(); searchDrop.style.background = \"transparent\"; });\n",
        "    searchDrop.addEventListener(\"drop\", (e) => { e.preventDefault(); searchFile.files = e.dataTransfer.files; searchDrop.style.background = \"transparent\"; });\n",
        "\n",
        "    // ارسال فرم‌ها با AJAX\n",
        "    const uploadForm = document.getElementById(\"uploadForm\");\n",
        "    uploadForm.addEventListener(\"submit\", function(e) {\n",
        "      e.preventDefault();\n",
        "      const finishProgress = simulateProgress(\"uploadProgressBar\", \"uploadProgressContainer\");\n",
        "      const formData = new FormData(uploadForm);\n",
        "      fetch(\"/\", { method: \"POST\", body: formData })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "         finishProgress();\n",
        "         const msgDiv = document.getElementById(\"uploadMessage\");\n",
        "         let htmlMsg = \"<p style='color:\" + (data.message.includes(\"تکراری\") ? \"red\" : \"green\") + \";'>\" + data.message + \"</p>\";\n",
        "         if(data.nudity_score) {\n",
        "           htmlMsg += \"<p>نودیتی: Sexy \" + data.nudity_score.sexy + \" - Porn \" + data.nudity_score.porn + \"</p>\";\n",
        "         }\n",
        "         if(data.rga && data.rga.category) {\n",
        "           htmlMsg += \"<p>RGA: <span class='rga-tag rga-\" + data.rga.category.toLowerCase() + \"'>\" + data.rga.category + \"</span></p>\";\n",
        "         }\n",
        "         msgDiv.innerHTML = htmlMsg;\n",
        "      });\n",
        "    });\n",
        "\n",
        "    const searchForm = document.getElementById(\"searchForm\");\n",
        "    searchForm.addEventListener(\"submit\", function(e) {\n",
        "      e.preventDefault();\n",
        "      const finishProgress = simulateProgress(\"searchProgressBar\", \"searchProgressContainer\");\n",
        "      const formData = new FormData(searchForm);\n",
        "      fetch(\"/search\", { method: \"POST\", body: formData })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "         finishProgress();\n",
        "         const msgDiv = document.getElementById(\"searchMessage\");\n",
        "         if(data.message){\n",
        "            msgDiv.innerHTML = \"<p style='color:green;'>\" + data.message + \"</p>\";\n",
        "         } else {\n",
        "            msgDiv.innerHTML = \"<p style='color:green;'>جستجو با موفقیت انجام شد.</p>\";\n",
        "         }\n",
        "      });\n",
        "    });\n",
        "\n",
        "    const recommendForm = document.getElementById(\"recommendForm\");\n",
        "    recommendForm.addEventListener(\"submit\", function(e) {\n",
        "      e.preventDefault();\n",
        "      const finishProgress = simulateProgress(\"recommendProgressBar\", \"recommendProgressContainer\");\n",
        "      const formData = new FormData(recommendForm);\n",
        "      fetch(\"/recommend\", { method: \"POST\", body: formData })\n",
        "      .then(response => response.json())\n",
        "      .then(data => {\n",
        "         finishProgress();\n",
        "         const resultsDiv = document.getElementById(\"recommendResults\");\n",
        "         if(data.length === 0) {\n",
        "           resultsDiv.innerHTML = \"<p>هیچ محتوایی برای توصیه یافت نشد.</p>\";\n",
        "         } else {\n",
        "           let html = \"<h4>پیشنهادها:</h4>\";\n",
        "           data.forEach(item => {\n",
        "             html += `<p>نام فایل: ${item.filename} - شباهت: ${item.cosine_similarity}% - هشتگ‌های مشترک: ${item.common_hashtags.join(\", \")}</p>`;\n",
        "           });\n",
        "           resultsDiv.innerHTML = html;\n",
        "         }\n",
        "      });\n",
        "    });\n",
        "\n",
        "    // بارگذاری محتوا بر اساس تب انتخاب شده\n",
        "    const tabs = document.querySelectorAll(\".tab\");\n",
        "    const contentArea = document.getElementById(\"content-area\");\n",
        "    function loadMedia(mediaType) {\n",
        "      fetch(\"/get_media/\" + mediaType)\n",
        "        .then(response => response.text())\n",
        "        .then(html => { contentArea.innerHTML = html; })\n",
        "        .catch(err => { contentArea.innerHTML = \"<p>خطا در بارگذاری محتوا</p>\"; });\n",
        "    }\n",
        "    tabs.forEach(tab => {\n",
        "      tab.addEventListener(\"click\", () => {\n",
        "        tabs.forEach(t => t.classList.remove(\"active\"));\n",
        "        tab.classList.add(\"active\");\n",
        "        loadMedia(tab.getAttribute(\"data-media\"));\n",
        "      });\n",
        "    });\n",
        "    document.addEventListener(\"DOMContentLoaded\", () => {\n",
        "      loadMedia(document.querySelector(\".tab.active\").getAttribute(\"data-media\"));\n",
        "    });\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# --------------------------\n",
        "# روت‌های آپلود، جستجو، توصیه و نمایش محتوا\n",
        "# --------------------------\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def upload_media():\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return jsonify({\"message\": \"فایل ارسال نشده است.\"})\n",
        "        file = request.files['file']\n",
        "        media_type = request.form.get(\"media_type\", \"image\")\n",
        "        if file.filename == '' or not allowed_file(file.filename, media_type):\n",
        "            return jsonify({\"message\": \"نوع فایل معتبر نیست.\"})\n",
        "        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "        file.save(file_path)\n",
        "\n",
        "        nudity_score = detect_nudity(file_path, media_type)\n",
        "        rga_result = RGA(file_path, media_type)\n",
        "        if media_type == \"image\" and rga_result[\"category\"] == \"R\":\n",
        "            os.remove(file_path)\n",
        "            logging.info(\"❌ محتوا به دلیل محتوای جنسی غیرمجاز ثبت نشد. (RGA: {})\".format(rga_result))\n",
        "            return jsonify({\n",
        "                \"message\": \"محتوا به دلیل محتوای جنسی غیرمجاز قابل ثبت نیست.\",\n",
        "                \"rga\": rga_result\n",
        "            })\n",
        "        hashtags = detect_entities(file_path, media_type)\n",
        "        fingerprint = generate_fingerprint(file_path, \"anonymous\", media_type)\n",
        "        if fingerprint:\n",
        "            fingerprinted_file_path = os.path.join(UPLOAD_FOLDER, \"fingerprinted_\" + file.filename)\n",
        "            embed_fingerprint(file_path, fingerprinted_file_path, fingerprint, media_type)\n",
        "        embedding = generate_embedding(file_path, media_type)\n",
        "        if embedding is None:\n",
        "            return jsonify({\"message\": \"❌ استخراج embedding ناموفق بود!\"})\n",
        "        duplicate_result = check_duplicate(file.filename, embedding, media_type, sim_threshold=0.9)\n",
        "        if duplicate_result[\"duplicate\"]:\n",
        "            return jsonify({\"message\": duplicate_result[\"message\"]})\n",
        "        if save_to_database(file.filename, file_path, embedding, nudity_score, hashtags, fingerprint, media_type):\n",
        "            logging.info(\"✅ اطلاعات محتوا به همراه هشتگ‌ها و فینگرپرینت در دیتابیس ذخیره شد.\")\n",
        "        index.add(embedding)\n",
        "        faiss.write_index(index, index_path)\n",
        "        return jsonify({\n",
        "            \"message\": \"عملیات ثبت محتوا با موفقیت انجام شد.\",\n",
        "            \"nudity_score\": nudity_score,\n",
        "            \"rga\": rga_result,\n",
        "            \"fingerprint\": fingerprint,\n",
        "            \"hashtags\": hashtags\n",
        "        })\n",
        "    return render_template_string(html_page)\n",
        "\n",
        "@app.route('/search', methods=['POST'])\n",
        "def search_media():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"message\": \"فایل ارسال نشده است.\"})\n",
        "    file = request.files['file']\n",
        "    media_type = request.form.get(\"media_type\", \"image\")\n",
        "    if file.filename == '' or not allowed_file(file.filename, media_type):\n",
        "        return jsonify({\"message\": \"نوع فایل معتبر نیست.\"})\n",
        "    file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "    file.save(file_path)\n",
        "    query_embedding = generate_embedding(file_path, media_type)\n",
        "    if query_embedding is None:\n",
        "         return jsonify({\"message\": \"خطا در استخراج ویژگی‌ها.\"})\n",
        "    embeddings, filenames, hashtags_list = load_embeddings_from_db(media_type)\n",
        "    if embeddings.shape[0] == 0:\n",
        "         return jsonify({\"message\": \"هیچ محتوایی در پایگاه داده موجود نیست.\"})\n",
        "    normalized_query = query_embedding / np.linalg.norm(query_embedding)\n",
        "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1\n",
        "    normalized_embeddings = embeddings / norms\n",
        "    cosine_similarities = np.dot(normalized_query, normalized_embeddings.T)[0]\n",
        "    similar_indices = np.where(cosine_similarities >= 0.6)[0]\n",
        "    similar_results = []\n",
        "    for idx in similar_indices:\n",
        "         similar_results.append({\n",
        "             \"filename\": filenames[idx],\n",
        "             \"similarity\": round(cosine_similarities[idx] * 100, 2),\n",
        "             \"hashtags\": hashtags_list[idx]\n",
        "         })\n",
        "    if similar_results:\n",
        "         return jsonify(similar_results)\n",
        "    else:\n",
        "         index_temp = faiss.IndexFlatL2(D)\n",
        "         index_temp.add(embeddings)\n",
        "         _, I_arr = index_temp.search(query_embedding, 1)\n",
        "         best_index = I_arr[0][0]\n",
        "         best_filename = filenames[best_index]\n",
        "         best_similarity = round(cosine_similarities[best_index] * 100, 2)\n",
        "         return jsonify([{\"filename\": best_filename, \"similarity\": best_similarity}])\n",
        "\n",
        "@app.route('/recommend', methods=['POST'])\n",
        "def recommend_media():\n",
        "    input_filename = request.form.get(\"inputFilename\")\n",
        "    media_type = request.form.get(\"media_type\", \"image\")\n",
        "    recommendations = recommend_content(input_filename, media_type, top_n=10)\n",
        "    return jsonify(recommendations)\n",
        "\n",
        "@app.route('/get_media_list/<media_type>')\n",
        "def get_media_list(media_type):\n",
        "    session_db = SessionLocal()\n",
        "    records = session_db.query(MediaEmbedding).filter_by(media_type=media_type).all()\n",
        "    session_db.close()\n",
        "    file_list = [{\"filename\": rec.filename} for rec in records]\n",
        "    return jsonify(file_list)\n",
        "\n",
        "@app.route('/get_media/<media_type>')\n",
        "def get_media(media_type):\n",
        "    session_db = SessionLocal()\n",
        "    records = session_db.query(MediaEmbedding).filter_by(media_type=media_type).all()\n",
        "    session_db.close()\n",
        "    html = \"\"\n",
        "    if not records:\n",
        "         html = \"<p>محتوایی وجود ندارد</p>\"\n",
        "    else:\n",
        "         for record in records:\n",
        "             file_url = \"/static/uploads/\" + record.filename\n",
        "             ext = os.path.splitext(record.filename)[1].lower()\n",
        "             if media_type == \"image\":\n",
        "                 thumb_html = f'<img src=\"{file_url}\" alt=\"{record.filename}\" class=\"thumbnail\">'\n",
        "             elif media_type == \"video\":\n",
        "                 thumb_html = f'<video src=\"{file_url}\" class=\"thumbnail\" controls></video>'\n",
        "             elif media_type == \"audio\":\n",
        "                 thumb_html = f'<audio src=\"{file_url}\" class=\"thumbnail\" controls></audio>'\n",
        "             elif media_type == \"text\":\n",
        "                 thumb_html = f'<div class=\"thumbnail text-thumbnail\">TXT</div>'\n",
        "             else:\n",
        "                 thumb_html = \"\"\n",
        "             file_format = ext[1:].upper() if ext.startswith('.') else ext.upper()\n",
        "             hashtags = record.hashtags if record.hashtags else \"\"\n",
        "             fingerprint = record.fingerprint if record.fingerprint else \"\"\n",
        "             html += f'''\n",
        "             <div class=\"media-card\">\n",
        "                 <div class=\"media-thumb\">{thumb_html}</div>\n",
        "                 <div class=\"media-info\">\n",
        "                     <h5>{record.filename}</h5>\n",
        "                     <p>فرمت: {file_format}</p>\n",
        "                     <p>هشتگ‌ها: {hashtags}</p>\n",
        "                     <p>فینگرپرینت: {fingerprint}</p>\n",
        "                 </div>\n",
        "             </div>\n",
        "             '''\n",
        "    return html\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"🌍 اجرا شده در: {public_url}\")\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSDHKsH7HDH2",
        "outputId": "30d33489-685e-480e-fe31-7f37741af1fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password: \n",
            "pg_dump: error: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n",
            "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: FATAL:  password authentication failed for user \"postgres\"\n"
          ]
        }
      ],
      "source": [
        "!pg_dump -U postgres -h localhost -p 5432 -F c -b -v -f /content/mydb_backup.dump mydb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDzQ4STLIGvo",
        "outputId": "0e93a301-82c3-4008-8608-37055325cdc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 2,588 B/129\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [3 InRelease 0 B/3,632 B 0%] [Waiting for headers] [Co\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,609 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,612 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,312 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,676 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.0 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,657 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Fetched 23.8 MB in 3s (6,853 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  hunspell\n",
            "The following NEW packages will be installed:\n",
            "  nano\n",
            "0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 280 kB of archives.\n",
            "After this operation, 881 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 nano amd64 6.2-1ubuntu0.1 [280 kB]\n",
            "Fetched 280 kB in 0s (2,543 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nano.\n",
            "(Reading database ... 126890 files and directories currently installed.)\n",
            "Preparing to unpack .../nano_6.2-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking nano (6.2-1ubuntu0.1) ...\n",
            "Setting up nano (6.2-1ubuntu0.1) ...\n",
            "update-alternatives: using /bin/nano to provide /usr/bin/editor (editor) in auto mode\n",
            "update-alternatives: using /bin/nano to provide /usr/bin/pico (pico) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install nano\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrYoJHwvI5Rv",
        "outputId": "c33ad49d-1b69-4226-93e5-d095d6aee65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 36588\n",
            "-rw-r--r-- 1 root root    49197 Feb 13 20:50 faiss.index\n",
            "-rw-r--r-- 1 root root        0 Feb 13 21:09 mydb_backup.dump\n",
            "drwxr-xr-x 3 root root     4096 Feb 13 17:20 nsfw_model\n",
            "drwxr-xr-x 1 root root     4096 Feb 11 14:27 sample_data\n",
            "drwxr-xr-x 3 root root     4096 Feb 13 17:32 static\n",
            "-rw-r--r-- 1 root root 14808437 Feb 13 17:32 yolov5s.pt\n",
            "-rw-r--r-- 1 root root 22588772 Feb 13 17:45 yolov8s.pt\n"
          ]
        }
      ],
      "source": [
        "!ls -l /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "RU1f5YCwmQhu",
        "outputId": "df05e992-f315-4ebe-bb40-4efea1623e5f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.python.training.tracking'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d8a85cba81d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Flask:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# The following imports may fail if TensorFlow is too old for TF2 features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1.14.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# pylint: disable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmart_cond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_structures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# pylint: enable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.training.tracking'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import flask\n",
        "import pyngrok\n",
        "import numpy\n",
        "import faiss\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import timm\n",
        "import tensorflow_hub\n",
        "\n",
        "print(\"Flask:\", flask.__version__)\n",
        "print(\"Pyngrok:\", pyngrok.__version__)\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"FAISS:\", faiss.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Timm:\", timm.__version__)\n",
        "print(\"TensorFlow Hub:\", tensorflow_hub.__version__)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3mI+mM1yv/nrn3d97k4sI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}